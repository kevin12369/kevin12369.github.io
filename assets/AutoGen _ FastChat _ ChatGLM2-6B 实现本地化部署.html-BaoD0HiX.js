import{_ as i,c as a,a as n,o as e}from"./app-BKGGKLrg.js";const h={};function t(l,s){return e(),a("div",null,[...s[0]||(s[0]=[n(`<h2 id="什么是autogen" tabindex="-1"><a class="header-anchor" href="#什么是autogen"><span>什么是AutoGen?</span></a></h2><p>Autogen 是一个由 Microsoft 推出的框架，它允许用户创建和管理多个自主代理，以协同完成复杂的任务。</p><p>这个框架的灵活性极高，你可以根据自己的需求定义不同的代理和它们的角色，然后让它们一起工作。</p><p>这种多代理协作的方式不仅提高了任务完成的效率，还提高了结果的质量，特别是在编程、规划和创意写作等领域。</p><h2 id="什么是chatglm2-6b" tabindex="-1"><a class="header-anchor" href="#什么是chatglm2-6b"><span>什么是ChatGLM2-6B？</span></a></h2><p>ChatGLM2-6B是智谱AI及清华KEG实验室发布的中英双语对话模型。</p><p>ChatGLM2-6B是开源的文本生成式对话模型,基于General Language Model(GLM)框架,具有62亿参数。 fp16 半精度下，ChatGLM-6B 需要至少 13GB 的显存进行推理，结合模型量化技术，这一需求可以进一步降低到 10GB（INT8） 和 6GB（INT4）， 使得 ChatGLM-6B 可以部署在消费级显卡上，人人都能上手一个大模型。ChatGLM-6B 使用了和 ChatGPT 相似的技术，针对中文问答和对话进行了优化。经过约 1T 标识符的中英双语训练，辅以监督微调、反馈自助、人类反馈强化学习等技术的加持，62 亿参数的 ChatGLM-6B 已经能生成相当符合人类偏好的回答。</p><p><a href="https://chatglm.cn/blog" target="_blank" rel="noopener noreferrer">智谱清言 (chatglm.cn)</a></p><h2 id="什么是fastchat" tabindex="-1"><a class="header-anchor" href="#什么是fastchat"><span>什么是FastChat？</span></a></h2><p>FastChat框架是一个训练、部署和评估大模型的开源平台，其核心特点是：</p><ul><li>提供SOTA模型的训练和评估代码</li><li>提供分布式多模型部署框架 + WebUI + OpenAI API</li></ul><h2 id="部署前先要做好的几个准备工作" tabindex="-1"><a class="header-anchor" href="#部署前先要做好的几个准备工作"><span>部署前先要做好的几个准备工作</span></a></h2><ul><li>确认自己电脑或者设备的CPU或者GPU型号，这很关键。</li><li>确认自己电脑的内存是否大于8G，这对于选择语言模型很关键。</li><li>通过设备CPU或者GPU型号，找到对应的torch、transformers和CUDA版本。</li></ul><h2 id="以-windows-11-为例开始搭建运行环境" tabindex="-1"><a class="header-anchor" href="#以-windows-11-为例开始搭建运行环境"><span>以 Windows 11 为例开始搭建运行环境</span></a></h2><ul><li>Anaconda 环境</li><li>git 环境</li><li>fastchat 环境</li><li>transformers 环境</li><li>torch 环境</li><li>autogen 环境</li><li>chatglm2-6b 环境</li></ul><h3 id="配置anaconda环境" tabindex="-1"><a class="header-anchor" href="#配置anaconda环境"><span>配置Anaconda环境</span></a></h3><h4 id="anaconda-官网下载地址" tabindex="-1"><a class="header-anchor" href="#anaconda-官网下载地址"><span>Anaconda 官网下载地址</span></a></h4><p><a href="https://www.anaconda.com/download/" target="_blank" rel="noopener noreferrer">Free Download | Anaconda --- 免费下载 |蟒蛇</a></p><h3 id="配置git环境" tabindex="-1"><a class="header-anchor" href="#配置git环境"><span>配置Git环境</span></a></h3><h4 id="git-官网下载地址" tabindex="-1"><a class="header-anchor" href="#git-官网下载地址"><span>Git 官网下载地址</span></a></h4><p><a href="https://gitforwindows.org/" target="_blank" rel="noopener noreferrer">Git for Windows --- 适用于 Windows 的 Git</a></p><h3 id="配置fastchat环境" tabindex="-1"><a class="header-anchor" href="#配置fastchat环境"><span>配置FastChat环境</span></a></h3><h4 id="从github上下载fastchat开源项目" tabindex="-1"><a class="header-anchor" href="#从github上下载fastchat开源项目"><span>从GitHub上下载FastChat开源项目</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">git</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> clone</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> https://github.com/lm-sys/FastChat.git</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="创建python虚拟运行环境" tabindex="-1"><a class="header-anchor" href="#创建python虚拟运行环境"><span>创建python虚拟运行环境</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">cd</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> FastChat</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">conda</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> create</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -n</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> autogen</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> python=</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">3.0</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -y</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">conda</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> activate</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> autogen</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">pip3</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> install</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> --upgrade</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> pip</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -i</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> https://pypi.mirrors.ustc.edu.cn/simple</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> --trusted-host=pypi.mirrors.ustc.edu.cn</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">pip3</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> install</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -e</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">.[model_worker,webui]</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -i</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> https://pypi.mirrors.ustc.edu.cn/simple</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> --trusted-host=pypi.mirrors.ustc.edu.cn</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="配置-transformers-环境" tabindex="-1"><a class="header-anchor" href="#配置-transformers-环境"><span>配置 transformers 环境</span></a></h3><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">pip3</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> uninstall</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -y</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> transformers</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">pip3</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> install</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> transformers==</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">4.30.2</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -i</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> https://pypi.mirrors.ustc.edu.cn/simple</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> --trusted-host=pypi.mirrors.ustc.edu.cn</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="配置torch环境" tabindex="-1"><a class="header-anchor" href="#配置torch环境"><span>配置torch环境</span></a></h3><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">pip3</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> install</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> torch==2.0.0+cu117</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> torchvision==0.15.1+cu117</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> torchaudio==</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">2.0.1</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> --index-url</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> https://download.pytorch.org/whl/cu117</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">pip3</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> install</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> cpm_kernels</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -i</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> https://pypi.mirrors.ustc.edu.cn/simple</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> --trusted-host=pypi.mirrors.ustc.edu.cn</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="配置autogen环境" tabindex="-1"><a class="header-anchor" href="#配置autogen环境"><span>配置autogen环境</span></a></h3><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">pip</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> install</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> pyautogen</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -i</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> https://pypi.mirrors.ustc.edu.cn/simple</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> --trusted-host=pypi.mirrors.ustc.edu.cn</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="下载chatglm2-6b模型" tabindex="-1"><a class="header-anchor" href="#下载chatglm2-6b模型"><span>下载Chatglm2-6b模型</span></a></h3><p>模型可从Hugging Face官网手动下载到/FastChat/ChatGLM-6B目录，没有目录的创建一个ChatGLM-6B目录（关键）。</p><h2 id="加载模型" tabindex="-1"><a class="header-anchor" href="#加载模型"><span>加载模型</span></a></h2><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># controller 控制器</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">cd</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> FastChat</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">conda</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> activate</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> autogen</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">python</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -m</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> fastchat.serve.controller</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> --host</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 0.0.0.0</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># model_worker 模型执行器</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">cd</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> FastChat</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">conda</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> activate</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> autogen</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">python</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -m</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> fastchat.serve.model_worker</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> --model-path</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> ChatGLM-6B</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># api_server API服务</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">cd</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> FastChat</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">conda</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> activate</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> autogen</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">python</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -m</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> fastchat.serve.openai_api_server</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> --host</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 0.0.0.0</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> --port</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 9527</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="测试代码" tabindex="-1"><a class="header-anchor" href="#测试代码"><span>测试代码</span></a></h2><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">from</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> autogen</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> import</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> oai</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">from</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> autogen</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> import</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> AssistantAgent,</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> UserProxyAgent,</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> config_list_from_json</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">def</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> TestAutoGen</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">()</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">:</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">    config_list</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> =</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> [</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">        {</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">            &quot;model&quot;</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">ChatGLM-6B</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">,</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">            &quot;base_url&quot;</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">http://127.0.0.1:9527/v1</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">,</span></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">            #&quot;api_type&quot;: &quot;open_ai&quot;,#该行要注释掉，不然报错</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">            &quot;api_key&quot;</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">NULL</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">        }</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    ]</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">    assistant</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> =</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> AssistantAgent</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">&quot;assistant&quot;</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">,</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> llm_config={</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">                               &quot;config_list&quot;</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">:</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> config_list}</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">    user_proxy</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> =</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> UserProxyAgent</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">        &quot;user_proxy&quot;</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">,</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> code_execution_config={</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">work_dir</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">coding</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">}</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">    user_proxy.initiate_chat(</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">        assistant,</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> message=</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">用react.js写一个用户登录程序</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">if</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;"> __name__</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> ==</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &#39;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">__main__</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&#39;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">:</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">    TestAutoGen</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">()</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="问题解决" tabindex="-1"><a class="header-anchor" href="#问题解决"><span>问题解决</span></a></h2><h4 id="问题1" tabindex="-1"><a class="header-anchor" href="#问题1"><span>问题1：</span></a></h4><p>启动FastChat的controller时报错： <code>ERROR: [Errno 99] error while attempting to bind on address (&#39;::1&#39;, 21001, 0, 0): cannot assign requested address</code> 这时，需要在需要在启动命令后加 - -host 0.0.0.0 <code>python -m fastchat.serve.controller --host 0.0.0.0</code></p><h4 id="问题2" tabindex="-1"><a class="header-anchor" href="#问题2"><span>问题2：</span></a></h4><p><code>AttributeError: &#39;ChatGLMTokenizer&#39; object has no attribute &#39;tokenizer&#39;. Did you mean: &#39;tokenize&#39;</code> 修改transformers的版本：<code>pip install transformers == 4.33.2</code></p><h4 id="问题3" tabindex="-1"><a class="header-anchor" href="#问题3"><span>问题3：</span></a></h4><p>有文档里autogen测试代码中ChatGLM的请求地址前参数写的是api_base，运行代码会报错，不能识别该参数。 <code>Completions.create() got an unexpected keyword argument &#39;api_base&#39;</code> 这时，需要把api_base要改成base_url。</p><h4 id="问题4" tabindex="-1"><a class="header-anchor" href="#问题4"><span>问题4：</span></a></h4><p>有文档里autogen测试代码中ChatGLM配置里包括api_type参数，运行代码会报错，不能识别该参数。 <code>Completions.create() got an unexpected keyword argument &#39;api_type&#39;</code> 这时，需要把该参数注释掉。</p><h4 id="问题5" tabindex="-1"><a class="header-anchor" href="#问题5"><span>问题5：</span></a></h4><p>运行代码会报错，测试代码中ChatGLM配置里model参数不能识别。 <code>openai.BadRequestError: Error code: 400 - {&#39;object&#39;: &#39;error&#39;, &#39;message&#39;: &#39;Only chatglm2-6b allowed now, your model ChatGLM-6B&#39;, &#39;code&#39;: 40301}</code> 这时，需要修改模型的名称，需要与FastChat的model_worker启动时的模型名称相同才会识别。</p><h4 id="问题6" tabindex="-1"><a class="header-anchor" href="#问题6"><span>问题6：</span></a></h4><p>当给大模型的任务需要执行python代码时，程序会使用到docker，没有安装docker的话就会报错。 <code>AttributeError: module &#39;docker&#39; has no attribute &#39;from_env&#39;</code> 这时，执行pip3 install docker。</p><h4 id="问题7" tabindex="-1"><a class="header-anchor" href="#问题7"><span>问题7：</span></a></h4><p>问题6安装docker后，执行仍报错。 <code>docker.errors.DockerException: Error while fetching server API version: (&#39;Connection aborted.&#39;, FileNotFoundError(2, &#39;No such file or directory&#39;))</code> 在代码的code_execution_config中添加&quot;use_docker&quot;:”python:3”，use_docker的值可以填docker镜像，填写镜像即是在镜像中执行模型自动生成的python代码，也可以什么都不填，什么都不填即是在本机运行，我这里因为是测试，就没有填实际的镜像。</p><h2 id="结论" tabindex="-1"><a class="header-anchor" href="#结论"><span>结论</span></a></h2><p>。</p>`,55)])])}const r=i(h,[["render",t]]),k=JSON.parse('{"path":"/news/aigc/AI%E6%A1%86%E6%9E%B6/AutoGen%20_%20FastChat%20_%20ChatGLM2-6B%20%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E5%8C%96%E9%83%A8%E7%BD%B2.html","title":"AutoGen + ChatGLM2-6B 实现本地化部署","lang":"zh-CN","frontmatter":{"icon":"edit","date":"2023-12-14T00:00:00.000Z","category":["GPT"],"tag":["AutoGen","ChatGLM2-6B"],"title":"AutoGen + ChatGLM2-6B 实现本地化部署"},"readingTime":{"minutes":4.38,"words":1313},"git":{"createdTime":1767508874000,"updatedTime":1767508874000,"contributors":[{"name":"kevin12369","username":"kevin12369","email":"491750329@qq.com","commits":1,"avatar":"https://avatars.githubusercontent.com/kevin12369?v=4","url":"https://github.com/kevin12369"}]},"filePathRelative":"news/aigc/AI框架/AutoGen + FastChat + ChatGLM2-6B 实现本地化部署.md","headers":[]}');export{r as comp,k as data};
