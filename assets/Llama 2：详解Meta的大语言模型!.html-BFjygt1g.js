import{_ as o}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as i,c as m,o as s,a as l,e as r,b as e,d as n}from"./app-HxMzW8nj.js";const p={},d={href:"https://juejin.cn/post/7311217582371274803",target:"_blank",rel:"noopener noreferrer"},u={href:"https://www.facebook.com/zuck/posts/10115001790074231",target:"_blank",rel:"noopener noreferrer"},L={href:"https://lmsys.org/blog/2023-03-30-vicuna/",target:"_blank",rel:"noopener noreferrer"},g={href:"https://ai.meta.com/resources/models-and-libraries/llama/",target:"_blank",rel:"noopener noreferrer"},f={href:"https://link.juejin.cn/?target=https%3A%2F%2Fakgeni.medium.com%2Fllama-concepts-explained-summary-a87f0bd61964",title:"https://akgeni.medium.com/llama-concepts-explained-summary-a87f0bd61964",target:"_blank",rel:"noopener noreferrer"},b={href:"https://link.juejin.cn/?target=https%3A%2F%2Fwww.techtarget.com%2Fsearchenterpriseai%2Fdefinition%2Freinforcement-learning",title:"https://www.techtarget.com/searchenterpriseai/definition/reinforcement-learning",target:"_blank",rel:"noopener noreferrer"},A={href:"https://link.juejin.cn/?target=https%3A%2F%2Fai.meta.com%2Fresources%2Fmodels-and-libraries%2Fllama%2F",title:"https://ai.meta.com/resources/models-and-libraries/llama/",target:"_blank",rel:"noopener noreferrer"},F={href:"https://link.juejin.cn/?target=https%3A%2F%2Fabout.fb.com%2Fnews%2F2023%2F08%2Fcode-llama-ai-for-coding%2F",title:"https://about.fb.com/news/2023/08/code-llama-ai-for-coding/",target:"_blank",rel:"noopener noreferrer"},I={href:"https://link.juejin.cn/?target=https%3A%2F%2Fabout.fb.com%2Fnews%2F2023%2F08%2Fcode-llama-ai-for-coding%2F",title:"https://about.fb.com/news/2023/08/code-llama-ai-for-coding/",target:"_blank",rel:"noopener noreferrer"};function k(h,a){const t=i("ExternalLinkIcon");return s(),m("div",null,[a[20]||(a[20]=l("p",null,"![[Pasted image 20240102160951.png]]",-1)),a[21]||(a[21]=l("h1",{id:"liama-2-详解meta的大语言模型",tabindex:"-1"},[l("a",{class:"header-anchor",href:"#liama-2-详解meta的大语言模型","aria-hidden":"true"},"#"),e(" LIama 2：详解Meta的大语言模型!")],-1)),l("p",null,[l("a",d,[a[0]||(a[0]=e("参考自Llama 2：详解Meta的大语言模型!",-1)),n(t)])]),a[22]||(a[22]=r('<blockquote><p>对Meta的Llama 2感兴趣吗？这里是一份相近的初学者指南，涵盖了从基础只是到高级技术规格，您所需要了解的一切。</p></blockquote><p>人工智能领域正迅猛发展，语言模型成为这场技术革新浪潮的尖兵。这些模型革新了我们与机器的交流方式，把曾经的科幻梦想变为我们日常生活的一部分。随着我们走进对话式AI越来越高级的新时代，Meta AI 推出的Llama 2 成为AI界的新亮点，为生成式AI的未来创新奠定了基础。</p><p>让我们深入探索这个开创性模型的更多细节。</p><h2 id="什么是llama" tabindex="-1"><a class="header-anchor" href="#什么是llama" aria-hidden="true">#</a> 什么是Llama?</h2><p>Llama（大型语言模型Meta AI）是一系列基础语言模型，参数规模从70亿到650亿不等，相较于GPT-3（1750亿参数）和PaLM（5400亿参数）等顶尖模型，Llama的规模较小。但尽管规模较小，Llama模型再各种基准测试中，如推理、编程、语言熟练度和知识测试等方面，都展现出了出色的表现。</p><p>Llama模型再计算效率和资源使用上也更加高效，这让哪些无法访问到大象基础设施的研究人员你和开发者能够更方便的使用它们。</p><p>现在，让我们稍微回顾一下Llama的来龙去脉。</p><p>在AI工具和社区的大肆宣传之下，Meta在2023年02月推出了他们独创的模型，取名为Llama。</p><p>![[Pasted image 20231214164339.png]]</p>',9)),l("p",null,[a[2]||(a[2]=e("图片来源：",-1)),l("a",u,[a[1]||(a[1]=e("扎克伯格的脸书",-1)),n(t)])]),a[23]||(a[23]=l("p",null,"有意思的是，Meta不同于其他AI大厂，他们选择将这个模型私有化，并且只与特定的研究者共享，以期进一步完善它。",-1)),a[24]||(a[24]=l("p",null,"然而，这个模型最终还是泄露给了公众。AI社区迅速拿到模型进行试验，并且优化得非常成功，不久之后，他们甚至把Llama模型搬到了手机上运行。一些人还在训练Llama的变种，如Vicuna，它能与Google的Bard相媲美，而成本却只有几百美元。",-1)),a[25]||(a[25]=l("p",null,"![[Pasted image 20231214164953.png]]",-1)),l("p",null,[a[4]||(a[4]=e("图片来源：",-1)),l("a",L,[a[3]||(a[3]=e("lmsys.org",-1)),n(t)])]),a[26]||(a[26]=l("h2",{id:"什么是llama-2以及它如何运作",tabindex:"-1"},[l("a",{class:"header-anchor",href:"#什么是llama-2以及它如何运作","aria-hidden":"true"},"#"),e(" 什么是Llama 2以及它如何运作？")],-1)),a[27]||(a[27]=l("p",null,"Llama 2是Meta打造的尖端语言模型，它是先前Llama的升级版，无论在规模、效能还是性能上都能有所提升。Llama 2模型的参数量介于70亿到700亿之间，能够适应各种计算能力和应用场景的需求。特别针对聊天机器人的集成，Llama 2在对话场景中表现卓越，能偶提供精准、流畅的回答，推动了对话式AI的发展极限。",-1)),a[28]||(a[28]=l("p",null,"![[Pasted image 20231214165652.png]]",-1)),l("p",null,[a[6]||(a[6]=e("图片来源：",-1)),l("a",g,[a[5]||(a[5]=e("Meta",-1)),n(t)])]),a[29]||(a[29]=r('<p>Llama 2利用公开的在线数据进行预先训练，这包括向模型提供大量的文本数据，如书籍、文章和其他书面材料。这样的预训练目的在于帮助模型掌握通用的语言模式，并广泛理解语言结构。此外，它还通过人类反馈进行监督式微调和强化学习（RLHF）。</p><p>RLHF中的一个关键环节是拒绝采样，即基于人类反馈对模型的回应进行选择，接受或拒绝。RLHF的另一个环节是近端策略优化（PRO），这一过程直接根据人类反馈调整模型策略。最终，通过迭代的精细调校，确保模型在经过监督的迭代和纠正后达到预期的性能标准。</p><h2 id="llama-2的优势" tabindex="-1"><a class="header-anchor" href="#llama-2的优势" aria-hidden="true">#</a> Llama 2的优势</h2><p>这里列举了一些Llama的显著优势，进一步证明了它为何是企业构建生成式AI应用的优选。</p><ul><li>开放性：该模型及其权重可以在社区许可下被下载，企业可以将其与自己的内部数据结合，并为特定场景进行微调，同时海恩那个保护隐私。</li><li>免费性：企业可以免费使用这个模型来打造自己的聊天机器人和其他应用，这意味着没有高昂的初始投入或者对Meta的授权费用，为那些希望低成本引入AI的公司提供了一种划算的选择。</li><li>多功能性：该模型提供多种尺寸，以适用不同的应用场景和平台，显示出其灵活性和适应性。</li><li>安全性：Llama 2经过了内外部的全面测试，以识别潜在的问题，如有害内容和偏见，这些都是AI部署时必须考虑的问题。附带的负责人使用智能为开发者提供了安全和负责人的AI开发与评估的最佳实践指导。</li></ul><h2 id="llama-2训练及数据集" tabindex="-1"><a class="header-anchor" href="#llama-2训练及数据集" aria-hidden="true">#</a> Llama 2训练及数据集</h2>',6)),l("p",null,[a[8]||(a[8]=e("Llama 2建立在Transformer结构之上，以其处理序列数据的高效而著称。它融入了若干创新要素，如",-1)),l("a",f,[a[7]||(a[7]=e("RMSNorm 预归一化、SwiGLU 激活函数和旋转嵌入技术",-1)),n(t)]),a[9]||(a[9]=e("。",-1))]),l("p",null,[a[11]||(a[11]=e("这些技术的加持使得Llama 2能够在长时间的对话中更好地保持语境，并在对话中精确关注到相关细节。它接收了大量数据集的预训练，确保在经过监督学习和",-1)),l("a",b,[a[10]||(a[10]=e("人类反馈强化学习",-1)),n(t)]),a[12]||(a[12]=e("的精细调教之前，已对语言的微妙差异有了深入理解。",-1))]),a[30]||(a[30]=l("p",null,"![[Pasted image 20231215103849.png]]",-1)),l("p",null,[a[14]||(a[14]=e("图片版权归属：",-1)),l("a",A,[a[13]||(a[13]=l("em",null,"Meta",-1)),n(t)])]),a[31]||(a[31]=l("p",null,"Liama 2经过强化学习的训练，旨在产生无毒害、适合家庭的用户优化型输出。其目标是更贴近人类，了解人们的选择和偏好。",-1)),a[32]||(a[32]=l("p",null,[l("strong",null,"Llama 2的训练基于一个庞大的数据集")],-1)),a[33]||(a[33]=l("p",null,"![[Pasted image 20231215104211.png]]",-1)),a[34]||(a[34]=l("p",null,"Llama 2模型系列包括7B、13B和70B参数的不同版本，满足不同需求和计算资源。这些参数的数量代表了模型能从训练数据中学习的方面。在语言模型领域，参数越多，通常意味着模型理解和生成类人文本的能力越强，因为他能从更多样的数据中学习。",-1)),a[35]||(a[35]=l("h2",{id:"llama-2-的优势和应用场景",tabindex:"-1"},[l("a",{class:"header-anchor",href:"#llama-2-的优势和应用场景","aria-hidden":"true"},"#"),e(" Llama 2 的优势和应用场景")],-1)),a[36]||(a[36]=l("p",null,"Llama 2最大的优势之一是其开源性，这为全球的开发者和研究人员创造了一个合作共享的环境。此外，它灵活的架构也支持个性化定制，使其成为各种应用场景下的多用途工具。",-1)),a[37]||(a[37]=l("p",null,"Llama 2还自豪于其高安全标准，它经过了严格的对抗性测试，以最小化有害输出。它的训练方法专注于上采样真是来源的信息，这是减少AI产生误导性信息的重要一步。Llama 2对其生成的内容有着良好的控制力，其准确性和上下文感知能力超越了市场上其他类似模型。",-1)),a[38]||(a[38]=l("p",null,"![[Pasted image 20231215105531.png]]",-1)),l("p",null,[a[16]||(a[16]=e("图片版权归属：",-1)),l("a",F,[a[15]||(a[15]=l("em",null,"Meta",-1)),n(t)])]),l("p",null,[a[18]||(a[18]=e("Llama 2的能力不止于聊天机器人；它还可以针对特定人物进行调整，如摘要、翻译和内容创作，成为各个领域内不可或缺的工具。在编程领域，‘",-1)),l("a",I,[a[17]||(a[17]=e("Code Llama",-1)),n(t)]),a[19]||(a[19]=e("’已被调整以辅助编程任务，有潜力革新开发者的编写和代码审查工作。",-1))]),a[39]||(a[39]=r('<h2 id="llama-2-与-openai-的-chatgpt-相比" tabindex="-1"><a class="header-anchor" href="#llama-2-与-openai-的-chatgpt-相比" aria-hidden="true">#</a> Llama 2 与 OpenAI 的 ChatGPT 相比</h2><p>尽管OpenAI 的 ChatGPT获得了更多的公众关注，但 Llama 2 带来的竞争不容小觑。Llama 2 的模型专为对话而优化，可能在交流互动中拥有更多优势。另外，Llama 2 的开源许可和可定制性为哪些希望在一个支持修改和在分发的平台上进行开噶的刃提供了选择。虽然ChatGPT作为更广泛的 GPT-3.5 和 GPT-4 生态系统的一部分而知名，以其强大的生成能力而闻名，但 Llama 2 在模型训练的透明度上可能更受学术界和研究领域人士的青睐，他们寻求突破AI的学习和拆改你在极限。</p><p>在我看来，Llama 2 不仅是 AI 领域的一大进步，更是跨入了一个新未来，在这个未来中，人机之恶能合作将更加紧密无缝。他的推出证明了 AI 领域的活力和不断向创新、安全和技术民主化迈进的决心。随着我们不断探索生成式 AI 的巨大潜能，Llama 2 是展示可能性能灯塔，预示着激动人心的未来进展。</p><h2 id="与llama-2-配合的-singlestoredb" tabindex="-1"><a class="header-anchor" href="#与llama-2-配合的-singlestoredb" aria-hidden="true">#</a> 与Llama 2 配合的 SingleStoreDB</h2><p>![[Pasted image 20231215110934.png]]</p><p>将Llama 2 与 SingleStoreDB结合，形成了先进的 AI 能力与强大数据管理的完美结合。SingleStoreDB在处理大型数据集方面的专长与 Llama 2 不同尺寸模型的需求相得益彰，保证了数据访问和处理的高效性。这种结合增强了系统的可拓展性，非常适合需要动态 AI 应用的场景。这种组合承诺提升实时 AI 性能。SingleStoreDB 快速的数据查询能力正好补充了Llama 2快数据检索和分析的需求。这种整合为创新的 AI 解决方案铺平了道路，尤其适用于需要快速决策和精密数据解读的场景。</p><h2 id="结论" tabindex="-1"><a class="header-anchor" href="#结论" aria-hidden="true">#</a> 结论</h2><p>随着 AI 领域以空前的速度发展，Llama 2 的问世以及 Meta 与 Microsoft 的合作，标志着行业的一个重要转折点。这一战略动作标志着向更大的透明度和合作开发的转变，为更广泛可用和先进的 AI 解决方案铺平了道路。Llama 2 凭借其在性能和易用性之间的平衡而脱颖而出。它被设计得像市场上其他模型一样安全甚至更安全，这一点鉴于 AI 输出可能的影响而显得尤为重要。</p>',8))])}const P=o(p,[["render",k],["__file","Llama 2：详解Meta的大语言模型!.html.vue"]]);export{P as default};
