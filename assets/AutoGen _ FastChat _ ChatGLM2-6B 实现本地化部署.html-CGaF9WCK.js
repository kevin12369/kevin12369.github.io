import{_ as i}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,a as n,o as e}from"./app-C4F5SHZ6.js";const t={};function h(l,s){return e(),a("div",null,[...s[0]||(s[0]=[n(`<h1 id="autogen-chatglm2-6b-实现本地化部署" tabindex="-1"><a class="header-anchor" href="#autogen-chatglm2-6b-实现本地化部署"><span>AutoGen + ChatGLM2-6B 实现本地化部署</span></a></h1><h2 id="什么是autogen" tabindex="-1"><a class="header-anchor" href="#什么是autogen"><span>什么是AutoGen?</span></a></h2><p>Autogen 是一个由 Microsoft 推出的框架，它允许用户创建和管理多个自主代理，以协同完成复杂的任务。</p><p>这个框架的灵活性极高，你可以根据自己的需求定义不同的代理和它们的角色，然后让它们一起工作。</p><p>这种多代理协作的方式不仅提高了任务完成的效率，还提高了结果的质量，特别是在编程、规划和创意写作等领域。</p><h2 id="什么是chatglm2-6b" tabindex="-1"><a class="header-anchor" href="#什么是chatglm2-6b"><span>什么是ChatGLM2-6B？</span></a></h2><p>ChatGLM2-6B是智谱AI及清华KEG实验室发布的中英双语对话模型。</p><p>ChatGLM2-6B是开源的文本生成式对话模型,基于General Language Model(GLM)框架,具有62亿参数。 fp16 半精度下，ChatGLM-6B 需要至少 13GB 的显存进行推理，结合模型量化技术，这一需求可以进一步降低到 10GB（INT8） 和 6GB（INT4）， 使得 ChatGLM-6B 可以部署在消费级显卡上，人人都能上手一个大模型。ChatGLM-6B 使用了和 ChatGPT 相似的技术，针对中文问答和对话进行了优化。经过约 1T 标识符的中英双语训练，辅以监督微调、反馈自助、人类反馈强化学习等技术的加持，62 亿参数的 ChatGLM-6B 已经能生成相当符合人类偏好的回答。</p><p><a href="https://chatglm.cn/blog" target="_blank" rel="noopener noreferrer">智谱清言 (chatglm.cn)</a></p><h2 id="什么是fastchat" tabindex="-1"><a class="header-anchor" href="#什么是fastchat"><span>什么是FastChat？</span></a></h2><p>FastChat框架是一个训练、部署和评估大模型的开源平台，其核心特点是：</p><ul><li>提供SOTA模型的训练和评估代码</li><li>提供分布式多模型部署框架 + WebUI + OpenAI API</li></ul><h2 id="部署前先要做好的几个准备工作" tabindex="-1"><a class="header-anchor" href="#部署前先要做好的几个准备工作"><span>部署前先要做好的几个准备工作</span></a></h2><ul><li>确认自己电脑或者设备的CPU或者GPU型号，这很关键。</li><li>确认自己电脑的内存是否大于8G，这对于选择语言模型很关键。</li><li>通过设备CPU或者GPU型号，找到对应的torch、transformers和CUDA版本。</li></ul><h2 id="以-windows-11-为例开始搭建运行环境" tabindex="-1"><a class="header-anchor" href="#以-windows-11-为例开始搭建运行环境"><span>以 Windows 11 为例开始搭建运行环境</span></a></h2><ul><li>Anaconda 环境</li><li>git 环境</li><li>fastchat 环境</li><li>transformers 环境</li><li>torch 环境</li><li>autogen 环境</li><li>chatglm2-6b 环境</li></ul><h3 id="配置anaconda环境" tabindex="-1"><a class="header-anchor" href="#配置anaconda环境"><span>配置Anaconda环境</span></a></h3><h4 id="anaconda-官网下载地址" tabindex="-1"><a class="header-anchor" href="#anaconda-官网下载地址"><span>Anaconda 官网下载地址</span></a></h4><p><a href="https://www.anaconda.com/download/" target="_blank" rel="noopener noreferrer">Free Download | Anaconda --- 免费下载 |蟒蛇</a></p><h3 id="配置git环境" tabindex="-1"><a class="header-anchor" href="#配置git环境"><span>配置Git环境</span></a></h3><h4 id="git-官网下载地址" tabindex="-1"><a class="header-anchor" href="#git-官网下载地址"><span>Git 官网下载地址</span></a></h4><p><a href="https://gitforwindows.org/" target="_blank" rel="noopener noreferrer">Git for Windows --- 适用于 Windows 的 Git</a></p><h3 id="配置fastchat环境" tabindex="-1"><a class="header-anchor" href="#配置fastchat环境"><span>配置FastChat环境</span></a></h3><h4 id="从github上下载fastchat开源项目" tabindex="-1"><a class="header-anchor" href="#从github上下载fastchat开源项目"><span>从GitHub上下载FastChat开源项目</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">git</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> clone</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> https://github.com/lm-sys/FastChat.git</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="创建python虚拟运行环境" tabindex="-1"><a class="header-anchor" href="#创建python虚拟运行环境"><span>创建python虚拟运行环境</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> FastChat</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">conda</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> create</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -n</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> autogen</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> python=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">3.0</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -y</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">conda</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> activate</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> autogen</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">pip3</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --upgrade</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> pip</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -i</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> https://pypi.mirrors.ustc.edu.cn/simple</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --trusted-host=pypi.mirrors.ustc.edu.cn</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">pip3</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -e</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;.[model_worker,webui]&quot;</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -i</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> https://pypi.mirrors.ustc.edu.cn/simple</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --trusted-host=pypi.mirrors.ustc.edu.cn</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="配置-transformers-环境" tabindex="-1"><a class="header-anchor" href="#配置-transformers-环境"><span>配置 transformers 环境</span></a></h3><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">pip3</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> uninstall</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -y</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> transformers</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">pip3</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> transformers==</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">4.30.2</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -i</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> https://pypi.mirrors.ustc.edu.cn/simple</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --trusted-host=pypi.mirrors.ustc.edu.cn</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="配置torch环境" tabindex="-1"><a class="header-anchor" href="#配置torch环境"><span>配置torch环境</span></a></h3><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">pip3</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> torch==2.0.0+cu117</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> torchvision==0.15.1+cu117</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> torchaudio==</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">2.0.1</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --index-url</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> https://download.pytorch.org/whl/cu117</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">pip3</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> cpm_kernels</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -i</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> https://pypi.mirrors.ustc.edu.cn/simple</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --trusted-host=pypi.mirrors.ustc.edu.cn</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="配置autogen环境" tabindex="-1"><a class="header-anchor" href="#配置autogen环境"><span>配置autogen环境</span></a></h3><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">pip</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> pyautogen</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -i</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> https://pypi.mirrors.ustc.edu.cn/simple</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --trusted-host=pypi.mirrors.ustc.edu.cn</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="下载chatglm2-6b模型" tabindex="-1"><a class="header-anchor" href="#下载chatglm2-6b模型"><span>下载Chatglm2-6b模型</span></a></h3><p>模型可从Hugging Face官网手动下载到/FastChat/ChatGLM-6B目录，没有目录的创建一个ChatGLM-6B目录（关键）。</p><h2 id="加载模型" tabindex="-1"><a class="header-anchor" href="#加载模型"><span>加载模型</span></a></h2><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># controller 控制器</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> FastChat</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">conda</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> activate</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> autogen</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">python</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -m</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> fastchat.serve.controller</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --host</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 0.0.0.0</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># model_worker 模型执行器</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> FastChat</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">conda</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> activate</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> autogen</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">python</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -m</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> fastchat.serve.model_worker</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --model-path</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ChatGLM-6B</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># api_server API服务</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> FastChat</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">conda</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> activate</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> autogen</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">python</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -m</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> fastchat.serve.openai_api_server</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --host</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 0.0.0.0</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --port</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 9527</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="测试代码" tabindex="-1"><a class="header-anchor" href="#测试代码"><span>测试代码</span></a></h2><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">from</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> autogen</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> import</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> oai</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">from</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> autogen</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> import</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> AssistantAgent,</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> UserProxyAgent,</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> config_list_from_json</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">def</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> TestAutoGen</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">:</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">    config_list</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> =</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        {</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">            &quot;model&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">:</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;ChatGLM-6B&quot;,</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">            &quot;base_url&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">:</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;http://127.0.0.1:9527/v1&quot;,</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">            #&quot;api_type&quot;: &quot;open_ai&quot;,#该行要注释掉，不然报错</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">            &quot;api_key&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">:</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;NULL&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        }</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    ]</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">    assistant</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> =</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> AssistantAgent</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">&quot;assistant&quot;</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">,</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> llm_config={</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">                               &quot;config_list&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">:</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> config_list}</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">    user_proxy</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> =</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> UserProxyAgent</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">        &quot;user_proxy&quot;</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">,</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> code_execution_config={&quot;work_dir&quot;:</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;coding&quot;}</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">    user_proxy.initiate_chat(</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">        assistant,</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> message=&quot;用react.js写一个用户登录程序&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> __name__</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ==</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;__main__&#39;:</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">    TestAutoGen</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="问题解决" tabindex="-1"><a class="header-anchor" href="#问题解决"><span>问题解决</span></a></h2><h4 id="问题1" tabindex="-1"><a class="header-anchor" href="#问题1"><span>问题1：</span></a></h4><p>启动FastChat的controller时报错：<br><code>ERROR: [Errno 99] error while attempting to bind on address (&#39;::1&#39;, 21001, 0, 0): cannot assign requested address</code><br> 这时，需要在需要在启动命令后加 - -host 0.0.0.0<br><code>python -m fastchat.serve.controller --host 0.0.0.0</code></p><h4 id="问题2" tabindex="-1"><a class="header-anchor" href="#问题2"><span>问题2：</span></a></h4><p><code>AttributeError: &#39;ChatGLMTokenizer&#39; object has no attribute &#39;tokenizer&#39;. Did you mean: &#39;tokenize&#39;</code><br> 修改transformers的版本：<code>pip install transformers == 4.33.2</code></p><h4 id="问题3" tabindex="-1"><a class="header-anchor" href="#问题3"><span>问题3：</span></a></h4><p>有文档里autogen测试代码中ChatGLM的请求地址前参数写的是api_base，运行代码会报错，不能识别该参数。<br><code>Completions.create() got an unexpected keyword argument &#39;api_base&#39;</code><br> 这时，需要把api_base要改成base_url。</p><h4 id="问题4" tabindex="-1"><a class="header-anchor" href="#问题4"><span>问题4：</span></a></h4><p>有文档里autogen测试代码中ChatGLM配置里包括api_type参数，运行代码会报错，不能识别该参数。<br><code>Completions.create() got an unexpected keyword argument &#39;api_type&#39;</code><br> 这时，需要把该参数注释掉。</p><h4 id="问题5" tabindex="-1"><a class="header-anchor" href="#问题5"><span>问题5：</span></a></h4><p>运行代码会报错，测试代码中ChatGLM配置里model参数不能识别。<br><code>openai.BadRequestError: Error code: 400 - {&#39;object&#39;: &#39;error&#39;, &#39;message&#39;: &#39;Only chatglm2-6b allowed now, your model ChatGLM-6B&#39;, &#39;code&#39;: 40301}</code><br> 这时，需要修改模型的名称，需要与FastChat的model_worker启动时的模型名称相同才会识别。</p><h4 id="问题6" tabindex="-1"><a class="header-anchor" href="#问题6"><span>问题6：</span></a></h4><p>当给大模型的任务需要执行python代码时，程序会使用到docker，没有安装docker的话就会报错。<br><code>AttributeError: module &#39;docker&#39; has no attribute &#39;from_env&#39;</code><br> 这时，执行pip3 install docker。</p><h4 id="问题7" tabindex="-1"><a class="header-anchor" href="#问题7"><span>问题7：</span></a></h4><p>问题6安装docker后，执行仍报错。<br><code>docker.errors.DockerException: Error while fetching server API version: (&#39;Connection aborted.&#39;, FileNotFoundError(2, &#39;No such file or directory&#39;))</code><br> 在代码的code_execution_config中添加&quot;use_docker&quot;:”python:3”，use_docker的值可以填docker镜像，填写镜像即是在镜像中执行模型自动生成的python代码，也可以什么都不填，什么都不填即是在本机运行，我这里因为是测试，就没有填实际的镜像。</p><h2 id="结论" tabindex="-1"><a class="header-anchor" href="#结论"><span>结论</span></a></h2><p>。</p>`,56)])])}const d=i(t,[["render",h]]),k=JSON.parse('{"path":"/news/aigc/AI%E6%A1%86%E6%9E%B6/AutoGen%20_%20FastChat%20_%20ChatGLM2-6B%20%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E5%8C%96%E9%83%A8%E7%BD%B2.html","title":"AutoGen + ChatGLM2-6B 实现本地化部署","lang":"zh-CN","frontmatter":{"icon":"edit","date":"2023-12-14T00:00:00.000Z","category":["GPT"],"tag":["AutoGen","ChatGLM2-6B"],"description":"AutoGen + ChatGLM2-6B 实现本地化部署 什么是AutoGen? Autogen 是一个由 Microsoft 推出的框架，它允许用户创建和管理多个自主代理，以协同完成复杂的任务。 这个框架的灵活性极高，你可以根据自己的需求定义不同的代理和它们的角色，然后让它们一起工作。 这种多代理协作的方式不仅提高了任务完成的效率，还提高了结果的质...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"AutoGen + ChatGLM2-6B 实现本地化部署\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2023-12-14T00:00:00.000Z\\",\\"dateModified\\":\\"2026-01-04T07:33:14.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Kevin\\",\\"url\\":\\"https://github.com/kevin12369\\"}]}"],["meta",{"property":"og:url","content":"https://kevin12369.github.io/news/aigc/AI%E6%A1%86%E6%9E%B6/AutoGen%20_%20FastChat%20_%20ChatGLM2-6B%20%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E5%8C%96%E9%83%A8%E7%BD%B2.html"}],["meta",{"property":"og:site_name","content":"Kevin的技术博客"}],["meta",{"property":"og:title","content":"AutoGen + ChatGLM2-6B 实现本地化部署"}],["meta",{"property":"og:description","content":"AutoGen + ChatGLM2-6B 实现本地化部署 什么是AutoGen? Autogen 是一个由 Microsoft 推出的框架，它允许用户创建和管理多个自主代理，以协同完成复杂的任务。 这个框架的灵活性极高，你可以根据自己的需求定义不同的代理和它们的角色，然后让它们一起工作。 这种多代理协作的方式不仅提高了任务完成的效率，还提高了结果的质..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2026-01-04T07:33:14.000Z"}],["meta",{"property":"article:tag","content":"ChatGLM2-6B"}],["meta",{"property":"article:tag","content":"AutoGen"}],["meta",{"property":"article:published_time","content":"2023-12-14T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2026-01-04T07:33:14.000Z"}]]},"git":{"createdTime":1767511994000,"updatedTime":1767511994000,"contributors":[{"name":"kevin12369","username":"kevin12369","email":"491750329@qq.com","commits":1,"url":"https://github.com/kevin12369"}]},"readingTime":{"minutes":4.38,"words":1313},"filePathRelative":"news/aigc/AI框架/AutoGen + FastChat + ChatGLM2-6B 实现本地化部署.md","excerpt":"\\n<h2>什么是AutoGen?</h2>\\n<p>Autogen 是一个由 Microsoft 推出的框架，它允许用户创建和管理多个自主代理，以协同完成复杂的任务。</p>\\n<p>这个框架的灵活性极高，你可以根据自己的需求定义不同的代理和它们的角色，然后让它们一起工作。</p>\\n<p>这种多代理协作的方式不仅提高了任务完成的效率，还提高了结果的质量，特别是在编程、规划和创意写作等领域。</p>\\n<h2>什么是ChatGLM2-6B？</h2>\\n<p>ChatGLM2-6B是智谱AI及清华KEG实验室发布的中英双语对话模型。</p>\\n<p>ChatGLM2-6B是开源的文本生成式对话模型,基于General Language Model(GLM)框架,具有62亿参数。 fp16 半精度下，ChatGLM-6B 需要至少 13GB 的显存进行推理，结合模型量化技术，这一需求可以进一步降低到 10GB（INT8） 和 6GB（INT4）， 使得 ChatGLM-6B 可以部署在消费级显卡上，人人都能上手一个大模型。ChatGLM-6B 使用了和 ChatGPT 相似的技术，针对中文问答和对话进行了优化。经过约 1T 标识符的中英双语训练，辅以监督微调、反馈自助、人类反馈强化学习等技术的加持，62 亿参数的 ChatGLM-6B 已经能生成相当符合人类偏好的回答。</p>","autoDesc":true}');export{d as comp,k as data};
