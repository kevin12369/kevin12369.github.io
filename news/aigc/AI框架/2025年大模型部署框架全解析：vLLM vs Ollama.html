<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="generator" content="VuePress 2.0.0-rc.0">
    <style>
      :root {
        --c-bg: #fff;
      }
      html.dark {
        --c-bg: #22272e;
      }
      html, body {
        background-color: var(--c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem('vuepress-color-scheme');
			const systemDarkMode = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;
			if (userMode === 'dark' || (userMode !== 'light' && systemDarkMode)) {
				document.documentElement.classList.toggle('dark', true);
			}
    </script>
    <meta name="keywords" content="AIå…¨æ ˆ,å‰ç«¯å¼€å‘,ç®—æ³•,æ¸¸æˆå¼€å‘,ç‰©è”ç½‘,AIGC"><meta name="author" content="Kevin"><meta name="robots" content="all"><title>2025å¹´å¤§æ¨¡å‹éƒ¨ç½²æ¡†æ¶å…¨è§£æï¼švLLM vs Ollama | Kevinçš„æŠ€æœ¯åšå®¢</title><meta name="description" content="ä¸€ä¸ªåœ¨æ³¥æ½­æŒ£æ‰çš„å·¥å…·äºº - æŠ€æœ¯åšå®¢ï¼Œæ¶µç›–AIå…¨æ ˆã€å‰ç«¯å¼€å‘ã€ç®—æ³•ã€æ¸¸æˆå¼€å‘ç­‰é¢†åŸŸ">
    <link rel="preload" href="/assets/style-DIdbiyZF.css" as="style"><link rel="stylesheet" href="/assets/style-DIdbiyZF.css">
    <link rel="modulepreload" href="/assets/app-D2t769wk.js"><link rel="modulepreload" href="/assets/2025å¹´å¤§æ¨¡å‹éƒ¨ç½²æ¡†æ¶å…¨è§£æï¼švLLM vs Ollama.html-Cz7YJ7g2.js"><link rel="modulepreload" href="/assets/2025å¹´å¤§æ¨¡å‹éƒ¨ç½²æ¡†æ¶å…¨è§£æï¼švLLM vs Ollama.html-Cs2-F-xQ.js">
    
  </head>
  <body>
    <div id="app"><!--[--><div class="theme-container"><!--[--><header class="navbar"><div class="toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a href="/" class=""><img class="logo" src="/logo.svg" alt="Kevinçš„æŠ€æœ¯åšå®¢"><span class="site-name can-hide">Kevinçš„æŠ€æœ¯åšå®¢</span></a></span><div class="navbar-items-wrapper" style=""><!--[--><!--]--><nav class="navbar-items can-hide"><!--[--><div class="navbar-item"><a href="/" class="" aria-label="é¦–é¡µ"><!--[--><!--]--> é¦–é¡µ <!--[--><!--]--></a></div><div class="navbar-item"><a href="/learning/" class="" aria-label="ğŸ“š æ·±åº¦å­¦ä¹ "><!--[--><!--]--> ğŸ“š æ·±åº¦å­¦ä¹  <!--[--><!--]--></a></div><div class="navbar-item"><a href="/projects/" class="" aria-label="ğŸ› ï¸ å®æˆ˜é¡¹ç›®"><!--[--><!--]--> ğŸ› ï¸ å®æˆ˜é¡¹ç›® <!--[--><!--]--></a></div><div class="navbar-item"><a href="/interview/" class="" aria-label="ğŸ’¡ é¢è¯•å‡†å¤‡"><!--[--><!--]--> ğŸ’¡ é¢è¯•å‡†å¤‡ <!--[--><!--]--></a></div><div class="navbar-item"><a href="/news/" class="router-link-active" aria-label="ğŸ“° æŠ€æœ¯èµ„è®¯"><!--[--><!--]--> ğŸ“° æŠ€æœ¯èµ„è®¯ <!--[--><!--]--></a></div><div class="navbar-item"><a href="/essays/" class="" aria-label="ğŸ“ ä¸ªäººéšç¬”"><!--[--><!--]--> ğŸ“ ä¸ªäººéšç¬” <!--[--><!--]--></a></div><div class="navbar-item"><a href="/tags/" class="" aria-label="ğŸ·ï¸ æ ‡ç­¾äº‘"><!--[--><!--]--> ğŸ·ï¸ æ ‡ç­¾äº‘ <!--[--><!--]--></a></div><!--]--></nav><!--[--><!--]--><button class="toggle-color-mode-button" title="toggle color mode"><svg class="icon" focusable="false" viewBox="0 0 32 32" style=""><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg class="icon" focusable="false" viewBox="0 0 32 32" style="display:none;"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><!----></div></header><!--]--><div class="sidebar-mask"></div><!--[--><aside class="sidebar"><nav class="navbar-items"><!--[--><div class="navbar-item"><a href="/" class="" aria-label="é¦–é¡µ"><!--[--><!--]--> é¦–é¡µ <!--[--><!--]--></a></div><div class="navbar-item"><a href="/learning/" class="" aria-label="ğŸ“š æ·±åº¦å­¦ä¹ "><!--[--><!--]--> ğŸ“š æ·±åº¦å­¦ä¹  <!--[--><!--]--></a></div><div class="navbar-item"><a href="/projects/" class="" aria-label="ğŸ› ï¸ å®æˆ˜é¡¹ç›®"><!--[--><!--]--> ğŸ› ï¸ å®æˆ˜é¡¹ç›® <!--[--><!--]--></a></div><div class="navbar-item"><a href="/interview/" class="" aria-label="ğŸ’¡ é¢è¯•å‡†å¤‡"><!--[--><!--]--> ğŸ’¡ é¢è¯•å‡†å¤‡ <!--[--><!--]--></a></div><div class="navbar-item"><a href="/news/" class="router-link-active" aria-label="ğŸ“° æŠ€æœ¯èµ„è®¯"><!--[--><!--]--> ğŸ“° æŠ€æœ¯èµ„è®¯ <!--[--><!--]--></a></div><div class="navbar-item"><a href="/essays/" class="" aria-label="ğŸ“ ä¸ªäººéšç¬”"><!--[--><!--]--> ğŸ“ ä¸ªäººéšç¬” <!--[--><!--]--></a></div><div class="navbar-item"><a href="/tags/" class="" aria-label="ğŸ·ï¸ æ ‡ç­¾äº‘"><!--[--><!--]--> ğŸ·ï¸ æ ‡ç­¾äº‘ <!--[--><!--]--></a></div><!--]--></nav><!--[--><!--]--><ul class="sidebar-items"><!--[--><li><p tabindex="0" class="sidebar-item sidebar-heading collapsible">AIGCèµ„è®¯ <span class="right arrow"></span></p><ul class="sidebar-item-children" style="display:none;"><!--[--><li><a href="/news/aigc/AI%E6%A1%86%E6%9E%B6/aigc/" class="sidebar-item" aria-label="aigc/"><!--[--><!--]--> aigc/ <!--[--><!--]--></a><!----></li><!--]--></ul></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="page"><!--[--><!--]--><div class="theme-default-content"><!--[--><!--]--><div><h1 id="_2025å¹´å¤§æ¨¡å‹éƒ¨ç½²æ¡†æ¶å…¨è§£æ-vllm-vs-ollama" tabindex="-1"><a class="header-anchor" href="#_2025å¹´å¤§æ¨¡å‹éƒ¨ç½²æ¡†æ¶å…¨è§£æ-vllm-vs-ollama" aria-hidden="true">#</a> 2025å¹´å¤§æ¨¡å‹éƒ¨ç½²æ¡†æ¶å…¨è§£æï¼švLLM vs Ollama</h1><blockquote><p>ä»ä¸ªäººå®éªŒåˆ°ä¼ä¸šç”Ÿäº§ï¼Œé€‰æ‹©æœ€é€‚åˆä½ çš„éƒ¨ç½²æ–¹æ¡ˆ</p></blockquote><h2 id="å¼•è¨€" tabindex="-1"><a class="header-anchor" href="#å¼•è¨€" aria-hidden="true">#</a> å¼•è¨€</h2><p>2025å¹´ï¼Œå¤§æ¨¡å‹æœ¬åœ°éƒ¨ç½²å·²æˆä¸ºAIåº”ç”¨è½åœ°çš„å…³é”®ç¯èŠ‚ã€‚éšç€vLLMå’ŒOllamaç­‰å¼€æºæ¡†æ¶çš„æˆç†Ÿï¼Œå¼€å‘è€…å¯ä»¥è½»æ¾åœ¨æœ¬åœ°è¿è¡Œå„ç±»å¼€æºå¤§è¯­è¨€æ¨¡å‹ã€‚æœ¬æ–‡å°†æ·±å…¥å¯¹æ¯”è¿™ä¸¤å¤§ä¸»æµéƒ¨ç½²æ¡†æ¶ï¼Œå¸®åŠ©ä½ é€‰æ‹©æœ€é€‚åˆçš„æ–¹æ¡ˆã€‚</p><h2 id="æ¡†æ¶æ¦‚è¿°" tabindex="-1"><a class="header-anchor" href="#æ¡†æ¶æ¦‚è¿°" aria-hidden="true">#</a> æ¡†æ¶æ¦‚è¿°</h2><h3 id="vllm-é«˜æ€§èƒ½æ¨ç†å¼•æ“" tabindex="-1"><a class="header-anchor" href="#vllm-é«˜æ€§èƒ½æ¨ç†å¼•æ“" aria-hidden="true">#</a> vLLMï¼šé«˜æ€§èƒ½æ¨ç†å¼•æ“</h3><p><strong>å®šä½ï¼š</strong> ä¼ä¸šçº§ã€é«˜æ€§èƒ½æ¨ç†æœåŠ¡</p><p><strong>èƒŒæ™¯ï¼š</strong></p><ul><li>å¼€å‘è€…ï¼šUC Berkeley SkyPilotå›¢é˜Ÿ</li><li>æ ¸å¿ƒæŠ€æœ¯ï¼šPagedAttentionã€å¼ é‡å¹¶è¡Œã€æµæ°´çº¿å¹¶è¡Œ</li><li>ç›®æ ‡ï¼šè§£å†³å¤§æ¨¡å‹æœåŠ¡ä¸­çš„æ˜¾å­˜æ•ˆç‡ä¸ååé‡ç“¶é¢ˆ</li></ul><p><strong>æ ¸å¿ƒä¼˜åŠ¿ï¼š</strong></p><ul><li>è¶…é«˜ååé‡</li><li>ä½å»¶è¿Ÿå“åº”</li><li>æ”¯æŒå¤šæ¨¡å‹å¹¶å‘</li><li>ä¼ä¸šçº§ç¨³å®šæ€§</li></ul><h3 id="ollama-æœ¬åœ°éƒ¨ç½²åˆ©å™¨" tabindex="-1"><a class="header-anchor" href="#ollama-æœ¬åœ°éƒ¨ç½²åˆ©å™¨" aria-hidden="true">#</a> Ollamaï¼šæœ¬åœ°éƒ¨ç½²åˆ©å™¨</h3><p><strong>å®šä½ï¼š</strong> ä¸ªäººå¼€å‘è€…ã€è½»é‡åŒ–åœºæ™¯</p><p><strong>èƒŒæ™¯ï¼š</strong></p><ul><li>å¼€å‘è€…ï¼šOllamaå›¢é˜Ÿï¼ˆåŸGitHub Copilotæ ¸å¿ƒæˆå‘˜ï¼‰</li><li>æ ¸å¿ƒæŠ€æœ¯ï¼šllama.cppã€GGUFæ ¼å¼</li><li>ç›®æ ‡ï¼šè®©å¼€å‘è€…è½»æ¾æœ¬åœ°è¿è¡Œå¤§æ¨¡å‹</li></ul><p><strong>æ ¸å¿ƒä¼˜åŠ¿ï¼š</strong></p><ul><li>å¼€ç®±å³ç”¨</li><li>è·¨å¹³å°æ”¯æŒ</li><li>ç®€å•æ˜“ç”¨</li><li>è½»é‡çº§éƒ¨ç½²</li></ul><h2 id="æŠ€æœ¯æ¶æ„å¯¹æ¯”" tabindex="-1"><a class="header-anchor" href="#æŠ€æœ¯æ¶æ„å¯¹æ¯”" aria-hidden="true">#</a> æŠ€æœ¯æ¶æ„å¯¹æ¯”</h2><h3 id="vllmæ¶æ„" tabindex="-1"><a class="header-anchor" href="#vllmæ¶æ„" aria-hidden="true">#</a> vLLMæ¶æ„</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">vLLMArchitecture</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># PagedAttentionï¼šåˆ†é¡µç¼“å­˜æœºåˆ¶</span>
        self<span class="token punctuation">.</span>paged_attention <span class="token operator">=</span> PagedAttention<span class="token punctuation">(</span>
            block_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
            num_gpu_blocks<span class="token operator">=</span><span class="token number">1024</span>
        <span class="token punctuation">)</span>
        
        <span class="token comment"># è¿ç»­æ‰¹å¤„ç†</span>
        self<span class="token punctuation">.</span>continuous_batching <span class="token operator">=</span> ContinuousBatching<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        <span class="token comment"># å¼ é‡å¹¶è¡Œ</span>
        self<span class="token punctuation">.</span>tensor_parallel <span class="token operator">=</span> TensorParallel<span class="token punctuation">(</span>
            world_size<span class="token operator">=</span><span class="token number">8</span>
        <span class="token punctuation">)</span>
        
        <span class="token comment"># æµæ°´çº¿å¹¶è¡Œ</span>
        self<span class="token punctuation">.</span>pipeline_parallel <span class="token operator">=</span> PipelineParallel<span class="token punctuation">(</span>
            num_stages<span class="token operator">=</span><span class="token number">4</span>
        <span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>å…³é”®æŠ€æœ¯ï¼š</strong></p><h4 id="_1-pagedattention" tabindex="-1"><a class="header-anchor" href="#_1-pagedattention" aria-hidden="true">#</a> 1. PagedAttention</h4><p><strong>åŸç†ï¼š</strong></p><ul><li>å°†KV Cacheåˆ†å—ç®¡ç†</li><li>æŒ‰éœ€åˆ†é…å’Œé‡Šæ”¾æ˜¾å­˜</li><li>æ”¯æŒè¶…é•¿ä¸Šä¸‹æ–‡</li></ul><p><strong>ä¼˜åŠ¿ï¼š</strong></p><ul><li>æ˜¾å­˜åˆ©ç”¨ç‡æå‡2-3å€</li><li>æ”¯æŒä¸Šä¸‡ä¸ªå¹¶å‘è¯·æ±‚</li><li>æ˜¾å­˜ç¢ç‰‡åŒ–å‡å°‘</li></ul><h4 id="_2-è¿ç»­æ‰¹å¤„ç†" tabindex="-1"><a class="header-anchor" href="#_2-è¿ç»­æ‰¹å¤„ç†" aria-hidden="true">#</a> 2. è¿ç»­æ‰¹å¤„ç†</h4><p><strong>åŠŸèƒ½ï¼š</strong></p><ul><li>åŠ¨æ€æ‰¹å¤„ç†ä¸åŒé•¿åº¦çš„è¯·æ±‚</li><li>æœ€å¤§åŒ–GPUåˆ©ç”¨ç‡</li><li>å‡å°‘æ¨ç†å»¶è¿Ÿ</li></ul><p><strong>ä»£ç ç¤ºä¾‹ï¼š</strong></p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> vllm <span class="token keyword">import</span> LLM<span class="token punctuation">,</span> SamplingParams

<span class="token comment"># åˆ›å»ºLLMå®ä¾‹</span>
llm <span class="token operator">=</span> LLM<span class="token punctuation">(</span>
    model<span class="token operator">=</span><span class="token string">&quot;meta-llama/Llama-3-8B&quot;</span><span class="token punctuation">,</span>
    tensor_parallel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
    gpu_memory_utilization<span class="token operator">=</span><span class="token number">0.9</span>
<span class="token punctuation">)</span>

<span class="token comment"># åˆ›å»ºé‡‡æ ·å‚æ•°</span>
sampling_params <span class="token operator">=</span> SamplingParams<span class="token punctuation">(</span>
    temperature<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">,</span>
    top_p<span class="token operator">=</span><span class="token number">0.95</span><span class="token punctuation">,</span>
    max_tokens<span class="token operator">=</span><span class="token number">1000</span>
<span class="token punctuation">)</span>

<span class="token comment"># æ¨ç†</span>
outputs <span class="token operator">=</span> llm<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>
    prompts<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&quot;è§£é‡Šé‡å­è®¡ç®—&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ &quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    sampling_params<span class="token operator">=</span>sampling_params
<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="ollamaæ¶æ„" tabindex="-1"><a class="header-anchor" href="#ollamaæ¶æ„" aria-hidden="true">#</a> Ollamaæ¶æ„</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">OllamaArchitecture</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># llama.cppæ ¸å¿ƒ</span>
        self<span class="token punctuation">.</span>llama_cpp <span class="token operator">=</span> LlamaCppEngine<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        <span class="token comment"># GGUFæ ¼å¼æ”¯æŒ</span>
        self<span class="token punctuation">.</span>gguf_loader <span class="token operator">=</span> GGUFLoader<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        <span class="token comment"># æ¨¡å‹ç®¡ç†</span>
        self<span class="token punctuation">.</span>model_manager <span class="token operator">=</span> ModelManager<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        <span class="token comment"># APIæœåŠ¡</span>
        self<span class="token punctuation">.</span>api_server <span class="token operator">=</span> APIServer<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>å…³é”®æŠ€æœ¯ï¼š</strong></p><h4 id="_1-ggufæ ¼å¼" tabindex="-1"><a class="header-anchor" href="#_1-ggufæ ¼å¼" aria-hidden="true">#</a> 1. GGUFæ ¼å¼</h4><p><strong>ç‰¹ç‚¹ï¼š</strong></p><ul><li>å‹ç¼©çš„æ¨¡å‹æƒé‡</li><li>æ”¯æŒé‡åŒ–ï¼ˆINT4ã€INT8ï¼‰</li><li>å¿«é€ŸåŠ è½½</li></ul><p><strong>ä¼˜åŠ¿ï¼š</strong></p><ul><li>æ¨¡å‹å¤§å°å‡å°‘50-75%</li><li>åŠ è½½é€Ÿåº¦æå‡3-5å€</li><li>å†…å­˜å ç”¨å¤§å¹…é™ä½</li></ul><h4 id="_2-æ¨¡å—åŒ–è®¾è®¡" tabindex="-1"><a class="header-anchor" href="#_2-æ¨¡å—åŒ–è®¾è®¡" aria-hidden="true">#</a> 2. æ¨¡å—åŒ–è®¾è®¡</h4><p><strong>æ¶æ„ï¼š</strong></p><div class="language-go line-numbers-mode" data-ext="go"><pre class="language-go"><code><span class="token comment">// æ¨¡å—åŒ–ç»„ä»¶</span>
<span class="token keyword">type</span> Ollama <span class="token keyword">struct</span> <span class="token punctuation">{</span>
    Model      ModelEngine
    Server     ServerEngine
    API        APIEngine
    CLI        CLIEngine
<span class="token punctuation">}</span>

<span class="token comment">// æ¨¡å‹å¼•æ“</span>
<span class="token keyword">type</span> ModelEngine <span class="token keyword">struct</span> <span class="token punctuation">{</span>
    GGUFLoader GGUFLoader
    Inference  InferenceEngine
    Cache      ModelCache
<span class="token punctuation">}</span>

<span class="token comment">// æ¨ç†å¼•æ“</span>
<span class="token keyword">type</span> InferenceEngine <span class="token keyword">struct</span> <span class="token punctuation">{</span>
    Context    InferenceContext
    Generator  TextGenerator
    Sampler    TokenSampler
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="åŠŸèƒ½å¯¹æ¯”" tabindex="-1"><a class="header-anchor" href="#åŠŸèƒ½å¯¹æ¯”" aria-hidden="true">#</a> åŠŸèƒ½å¯¹æ¯”</h2><h3 id="_1-æ¨¡å‹æ”¯æŒ" tabindex="-1"><a class="header-anchor" href="#_1-æ¨¡å‹æ”¯æŒ" aria-hidden="true">#</a> 1. æ¨¡å‹æ”¯æŒ</h3><table><thead><tr><th>ç‰¹æ€§</th><th>vLLM</th><th>Ollama</th></tr></thead><tbody><tr><td>æ”¯æŒæ¨¡å‹</td><td>Hugging Faceæ‰€æœ‰æ¨¡å‹ï¼ˆfp16/bf16ï¼‰</td><td>GGUFæ ¼å¼æ¨¡å‹ï¼ˆLlamaã€Qwenã€Mistralç­‰ï¼‰</td></tr><tr><td>æ¨¡å‹æ ¼å¼</td><td>PyTorchã€Safetensors</td><td>GGUF</td></tr><tr><td>æ¨¡å‹é‡åŒ–</td><td>FP16ã€BF16ã€INT8</td><td>INT4ã€INT8ã€FP16</td></tr><tr><td>è‡ªå®šä¹‰æ¨¡å‹</td><td>éœ€è¦è½¬æ¢ä¸ºPyTorchæ ¼å¼</td><td>æ”¯æŒè‡ªå®šä¹‰GGUFæ¨¡å‹</td></tr></tbody></table><h3 id="_2-éƒ¨ç½²æ–¹å¼" tabindex="-1"><a class="header-anchor" href="#_2-éƒ¨ç½²æ–¹å¼" aria-hidden="true">#</a> 2. éƒ¨ç½²æ–¹å¼</h3><h4 id="vllméƒ¨ç½²" tabindex="-1"><a class="header-anchor" href="#vllméƒ¨ç½²" aria-hidden="true">#</a> vLLMéƒ¨ç½²</h4><p><strong>æ–¹å¼1ï¼šPython API</strong></p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> vllm <span class="token keyword">import</span> LLM<span class="token punctuation">,</span> SamplingParams

llm <span class="token operator">=</span> LLM<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">&quot;meta-llama/Llama-3-8B&quot;</span><span class="token punctuation">)</span>
outputs <span class="token operator">=</span> llm<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>prompts<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&quot;ä½ å¥½&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> sampling_params<span class="token operator">=</span>SamplingParams<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>æ–¹å¼2ï¼šOpenAIå…¼å®¹API</strong></p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># å¯åŠ¨vLLMæœåŠ¡å™¨</span>
python <span class="token parameter variable">-m</span> vllm.entrypoints.openai.api_server <span class="token punctuation">\</span>
    <span class="token parameter variable">--model</span> meta-llama/Llama-3-8B <span class="token punctuation">\</span>
    <span class="token parameter variable">--port</span> <span class="token number">8000</span>

<span class="token comment"># è°ƒç”¨API</span>
<span class="token function">curl</span> http://localhost:8000/v1/completions <span class="token punctuation">\</span>
  <span class="token parameter variable">-H</span> <span class="token string">&quot;Content-Type: application/json&quot;</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">-d</span> <span class="token string">&#39;{
    &quot;model&quot;: &quot;meta-llama/Llama-3-8B&quot;,
    &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;ä½ å¥½&quot;}]
  }&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>æ–¹å¼3ï¼šDockeréƒ¨ç½²</strong></p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># æ‹‰å–é•œåƒ</span>
<span class="token function">docker</span> pull vllm/vllm-openai:latest

<span class="token comment"># è¿è¡Œå®¹å™¨</span>
<span class="token function">docker</span> run <span class="token parameter variable">--gpus</span> all <span class="token punctuation">\</span>
    <span class="token parameter variable">-p</span> <span class="token number">8000</span>:8000 <span class="token punctuation">\</span>
    --shm-size<span class="token operator">=</span>10g <span class="token punctuation">\</span>
    vllm/vllm-openai:latest <span class="token punctuation">\</span>
    <span class="token parameter variable">--model</span> meta-llama/Llama-3-8B
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="ollamaéƒ¨ç½²" tabindex="-1"><a class="header-anchor" href="#ollamaéƒ¨ç½²" aria-hidden="true">#</a> Ollamaéƒ¨ç½²</h4><p><strong>æ–¹å¼1ï¼šå‘½ä»¤è¡Œäº¤äº’</strong></p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># å®‰è£…Ollama</span>
<span class="token function">curl</span> <span class="token parameter variable">-fsSL</span> https://ollama.com/install.sh <span class="token operator">|</span> <span class="token function">sh</span>

<span class="token comment"># æ‹‰å–æ¨¡å‹</span>
ollama pull llama3:8b

<span class="token comment"># è¿è¡Œæ¨¡å‹</span>
ollama run llama3:8b <span class="token string">&quot;ä½ å¥½&quot;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>æ–¹å¼2ï¼šAPIæœåŠ¡</strong></p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># å¯åŠ¨APIæœåŠ¡</span>
ollama serve

<span class="token comment"># è°ƒç”¨API</span>
<span class="token function">curl</span> http://localhost:11434/api/generate <span class="token punctuation">\</span>
  <span class="token parameter variable">-d</span> <span class="token string">&#39;{
    &quot;model&quot;: &quot;llama3:8b&quot;,
    &quot;prompt&quot;: &quot;ä½ å¥½&quot;
  }&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>æ–¹å¼3ï¼šPython SDK</strong></p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> ollama

<span class="token comment"># åŠ è½½æ¨¡å‹</span>
llm <span class="token operator">=</span> ollama<span class="token punctuation">.</span>pull<span class="token punctuation">(</span><span class="token string">&quot;llama3:8b&quot;</span><span class="token punctuation">)</span>

<span class="token comment"># ç”Ÿæˆæ–‡æœ¬</span>
response <span class="token operator">=</span> ollama<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>
    model<span class="token operator">=</span><span class="token string">&quot;llama3:8b&quot;</span><span class="token punctuation">,</span>
    prompt<span class="token operator">=</span><span class="token string">&quot;ä½ å¥½&quot;</span>
<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_3-æ€§èƒ½å¯¹æ¯”" tabindex="-1"><a class="header-anchor" href="#_3-æ€§èƒ½å¯¹æ¯”" aria-hidden="true">#</a> 3. æ€§èƒ½å¯¹æ¯”</h3><h4 id="ååé‡å¯¹æ¯”" tabindex="-1"><a class="header-anchor" href="#ååé‡å¯¹æ¯”" aria-hidden="true">#</a> ååé‡å¯¹æ¯”</h4><table><thead><tr><th>æ¨¡å‹</th><th>vLLM</th><th>Ollama</th></tr></thead><tbody><tr><td>Llama 3-8B</td><td>500+ tokens/s</td><td>50-100 tokens/s</td></tr><tr><td>Llama 3-70B</td><td>200+ tokens/s</td><td>20-40 tokens/s</td></tr><tr><td>Qwen3-72B</td><td>300+ tokens/s</td><td>30-60 tokens/s</td></tr></tbody></table><p><strong>æµ‹è¯•ç¯å¢ƒï¼š</strong></p><ul><li>GPU: NVIDIA A100 80GB</li><li>Batch Size: 1</li><li>Max Tokens: 1000</li></ul><h4 id="å»¶è¿Ÿå¯¹æ¯”" tabindex="-1"><a class="header-anchor" href="#å»¶è¿Ÿå¯¹æ¯”" aria-hidden="true">#</a> å»¶è¿Ÿå¯¹æ¯”</h4><table><thead><tr><th>åœºæ™¯</th><th>vLLM</th><th>Ollama</th></tr></thead><tbody><tr><td>é¦–å­—å»¶è¿Ÿ</td><td>&lt;100ms</td><td>200-500ms</td></tr><tr><td>å¹³å‡å»¶è¿Ÿ</td><td>50-100ms</td><td>100-300ms</td></tr><tr><td>P99å»¶è¿Ÿ</td><td>200-500ms</td><td>500-1000ms</td></tr></tbody></table><h4 id="å¹¶å‘èƒ½åŠ›" tabindex="-1"><a class="header-anchor" href="#å¹¶å‘èƒ½åŠ›" aria-hidden="true">#</a> å¹¶å‘èƒ½åŠ›</h4><table><thead><tr><th>å¹¶å‘æ•°</th><th>vLLM</th><th>Ollama</th></tr></thead><tbody><tr><td>10</td><td>ç¨³å®š</td><td>ç¨³å®š</td></tr><tr><td>50</td><td>ç¨³å®š</td><td>å»¶è¿Ÿå¢åŠ </td></tr><tr><td>100</td><td>ç¨³å®š</td><td>å¯èƒ½å´©æºƒ</td></tr><tr><td>1000</td><td>ç¨³å®š</td><td>ä¸æ”¯æŒ</td></tr></tbody></table><h3 id="_4-èµ„æºéœ€æ±‚" tabindex="-1"><a class="header-anchor" href="#_4-èµ„æºéœ€æ±‚" aria-hidden="true">#</a> 4. èµ„æºéœ€æ±‚</h3><h4 id="ç¡¬ä»¶éœ€æ±‚" tabindex="-1"><a class="header-anchor" href="#ç¡¬ä»¶éœ€æ±‚" aria-hidden="true">#</a> ç¡¬ä»¶éœ€æ±‚</h4><table><thead><tr><th>æ¨¡å‹</th><th>vLLM</th><th>Ollama</th></tr></thead><tbody><tr><td>Llama 3-8B</td><td>16GB</td><td>8GB (INT4)</td></tr><tr><td>Llama 3-70B</td><td>140GB</td><td>70GB (INT4)</td></tr><tr><td>Qwen3-72B</td><td>144GB</td><td>72GB (INT4)</td></tr></tbody></table><h4 id="å†…å­˜å ç”¨" tabindex="-1"><a class="header-anchor" href="#å†…å­˜å ç”¨" aria-hidden="true">#</a> å†…å­˜å ç”¨</h4><table><thead><tr><th>æ¨¡å‹</th><th>vLLM (FP16)</th><th>Ollama (INT4)</th></tr></thead><tbody><tr><td>Llama 3-8B</td><td>16GB</td><td>6GB</td></tr><tr><td>Llama 3-70B</td><td>140GB</td><td>38GB</td></tr><tr><td>Qwen3-72B</td><td>144GB</td><td>40GB</td></tr></tbody></table><h2 id="åº”ç”¨åœºæ™¯" tabindex="-1"><a class="header-anchor" href="#åº”ç”¨åœºæ™¯" aria-hidden="true">#</a> åº”ç”¨åœºæ™¯</h2><h3 id="vllmé€‚ç”¨åœºæ™¯" tabindex="-1"><a class="header-anchor" href="#vllmé€‚ç”¨åœºæ™¯" aria-hidden="true">#</a> vLLMé€‚ç”¨åœºæ™¯</h3><h4 id="_1-ä¼ä¸šçº§æœåŠ¡" tabindex="-1"><a class="header-anchor" href="#_1-ä¼ä¸šçº§æœåŠ¡" aria-hidden="true">#</a> 1. ä¼ä¸šçº§æœåŠ¡</h4><p><strong>åœºæ™¯ï¼š</strong></p><ul><li>é«˜å¹¶å‘APIæœåŠ¡</li><li>å®æ—¶å¯¹è¯ç³»ç»Ÿ</li><li>æ‰¹é‡æ–‡æ¡£å¤„ç†</li></ul><p><strong>ä¼˜åŠ¿ï¼š</strong></p><ul><li>é«˜ååé‡</li><li>ä½å»¶è¿Ÿ</li><li>ç¨³å®šå¯é </li></ul><h4 id="_2-å¤šæ¨¡å‹æœåŠ¡" tabindex="-1"><a class="header-anchor" href="#_2-å¤šæ¨¡å‹æœåŠ¡" aria-hidden="true">#</a> 2. å¤šæ¨¡å‹æœåŠ¡</h4><p><strong>åœºæ™¯ï¼š</strong></p><ul><li>åŒæ—¶æœåŠ¡å¤šä¸ªæ¨¡å‹</li><li>æ¨¡å‹A/Bæµ‹è¯•</li><li>åŠ¨æ€æ¨¡å‹åˆ‡æ¢</li></ul><p><strong>å®ç°ï¼š</strong></p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> vllm <span class="token keyword">import</span> LLM<span class="token punctuation">,</span> SamplingParams

<span class="token comment"># åŠ è½½å¤šä¸ªæ¨¡å‹</span>
llama <span class="token operator">=</span> LLM<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">&quot;meta-llama/Llama-3-8B&quot;</span><span class="token punctuation">)</span>
qwen <span class="token operator">=</span> LLM<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">&quot;Qwen/Qwen2.5-7B&quot;</span><span class="token punctuation">)</span>

<span class="token comment"># åˆ›å»ºé‡‡æ ·å‚æ•°</span>
sampling_params <span class="token operator">=</span> SamplingParams<span class="token punctuation">(</span>temperature<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">)</span>

<span class="token comment"># å¹¶å‘æ¨ç†</span>
results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> prompt <span class="token keyword">in</span> prompts<span class="token punctuation">:</span>
    <span class="token keyword">if</span> <span class="token string">&quot;ä¸­æ–‡&quot;</span> <span class="token keyword">in</span> prompt<span class="token punctuation">:</span>
        results<span class="token punctuation">.</span>append<span class="token punctuation">(</span>qwen<span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token punctuation">[</span>prompt<span class="token punctuation">]</span><span class="token punctuation">,</span> sampling_params<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        results<span class="token punctuation">.</span>append<span class="token punctuation">(</span>llama<span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token punctuation">[</span>prompt<span class="token punctuation">]</span><span class="token punctuation">,</span> sampling_params<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_3-åˆ†å¸ƒå¼éƒ¨ç½²" tabindex="-1"><a class="header-anchor" href="#_3-åˆ†å¸ƒå¼éƒ¨ç½²" aria-hidden="true">#</a> 3. åˆ†å¸ƒå¼éƒ¨ç½²</h4><p><strong>åœºæ™¯ï¼š</strong></p><ul><li>å¤§è§„æ¨¡é›†ç¾¤éƒ¨ç½²</li><li>è¶…å¤§æ¨¡å‹æ¨ç†</li><li>è´Ÿè½½å‡è¡¡</li></ul><p><strong>æ¶æ„ï¼š</strong></p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> vllm <span class="token keyword">import</span> LLM

<span class="token comment"># åˆ†å¸ƒå¼æ¨ç†</span>
llm <span class="token operator">=</span> LLM<span class="token punctuation">(</span>
    model<span class="token operator">=</span><span class="token string">&quot;meta-llama/Llama-3-405B&quot;</span><span class="token punctuation">,</span>
    tensor_parallel_size<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>
    pipeline_parallel_size<span class="token operator">=</span><span class="token number">4</span>
<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="ollamaé€‚ç”¨åœºæ™¯" tabindex="-1"><a class="header-anchor" href="#ollamaé€‚ç”¨åœºæ™¯" aria-hidden="true">#</a> Ollamaé€‚ç”¨åœºæ™¯</h3><h4 id="_1-ä¸ªäººå¼€å‘å®éªŒ" tabindex="-1"><a class="header-anchor" href="#_1-ä¸ªäººå¼€å‘å®éªŒ" aria-hidden="true">#</a> 1. ä¸ªäººå¼€å‘å®éªŒ</h4><p><strong>åœºæ™¯ï¼š</strong></p><ul><li>å¿«é€Ÿä½“éªŒæ–°æ¨¡å‹</li><li>æœ¬åœ°æµ‹è¯•å’Œè°ƒè¯•</li><li>å­¦ä¹ å’Œç ”ç©¶</li></ul><p><strong>ä¼˜åŠ¿ï¼š</strong></p><ul><li>ä¸€é”®éƒ¨ç½²</li><li>ç®€å•æ˜“ç”¨</li><li>èµ„æºå ç”¨ä½</li></ul><h4 id="_2-è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²" tabindex="-1"><a class="header-anchor" href="#_2-è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²" aria-hidden="true">#</a> 2. è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²</h4><p><strong>åœºæ™¯ï¼š</strong></p><ul><li>æ ‘è“æ´¾éƒ¨ç½²</li><li>ç¬”è®°æœ¬æœ¬åœ°è¿è¡Œ</li><li>ç¦»çº¿ç¯å¢ƒ</li></ul><p><strong>ä¼˜åŠ¿ï¼š</strong></p><ul><li>è½»é‡çº§</li><li>è·¨å¹³å°</li><li>ä½åŠŸè€—</li></ul><h4 id="_3-åŸå‹å¼€å‘" tabindex="-1"><a class="header-anchor" href="#_3-åŸå‹å¼€å‘" aria-hidden="true">#</a> 3. åŸå‹å¼€å‘</h4><p><strong>åœºæ™¯ï¼š</strong></p><ul><li>å¿«é€ŸéªŒè¯æƒ³æ³•</li><li>æ¦‚å¿µéªŒè¯ï¼ˆPOCï¼‰</li><li>æŠ€æœ¯é€‰å‹</li></ul><p><strong>ä¼˜åŠ¿ï¼š</strong></p><ul><li>å¿«é€Ÿè¿­ä»£</li><li>ä½æˆæœ¬</li><li>æ˜“äºè°ƒè¯•</li></ul><h2 id="æœ€ä½³å®è·µ" tabindex="-1"><a class="header-anchor" href="#æœ€ä½³å®è·µ" aria-hidden="true">#</a> æœ€ä½³å®è·µ</h2><h3 id="vllmæœ€ä½³å®è·µ" tabindex="-1"><a class="header-anchor" href="#vllmæœ€ä½³å®è·µ" aria-hidden="true">#</a> vLLMæœ€ä½³å®è·µ</h3><h4 id="_1-ä¼˜åŒ–é…ç½®" tabindex="-1"><a class="header-anchor" href="#_1-ä¼˜åŒ–é…ç½®" aria-hidden="true">#</a> 1. ä¼˜åŒ–é…ç½®</h4><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> vllm <span class="token keyword">import</span> LLM

<span class="token comment"># ä¼˜åŒ–é…ç½®</span>
llm <span class="token operator">=</span> LLM<span class="token punctuation">(</span>
    model<span class="token operator">=</span><span class="token string">&quot;meta-llama/Llama-3-8B&quot;</span><span class="token punctuation">,</span>
    <span class="token comment"># å¼ é‡å¹¶è¡Œ</span>
    tensor_parallel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
    <span class="token comment"># GPUå†…å­˜åˆ©ç”¨ç‡</span>
    gpu_memory_utilization<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span>
    <span class="token comment"># æœ€å¤§æ¨¡å‹é•¿åº¦</span>
    max_model_len<span class="token operator">=</span><span class="token number">8192</span><span class="token punctuation">,</span>
    <span class="token comment"># KV Cacheè®¾ç½®</span>
    block_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    <span class="token comment"># å¯ç”¨CUDAå›¾</span>
    enable_prefix_caching<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_2-ç›‘æ§ä¸æ—¥å¿—" tabindex="-1"><a class="header-anchor" href="#_2-ç›‘æ§ä¸æ—¥å¿—" aria-hidden="true">#</a> 2. ç›‘æ§ä¸æ—¥å¿—</h4><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> vllm<span class="token punctuation">.</span>engine<span class="token punctuation">.</span>arg_utils <span class="token keyword">import</span> EngineArgs

<span class="token comment"># å¯ç”¨è¯¦ç»†æ—¥å¿—</span>
engine_args <span class="token operator">=</span> EngineArgs<span class="token punctuation">(</span>
    model<span class="token operator">=</span><span class="token string">&quot;meta-llama/Llama-3-8B&quot;</span><span class="token punctuation">,</span>
    disable_log_stats<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
    disable_log_requests<span class="token operator">=</span><span class="token boolean">False</span>
<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_3-é”™è¯¯å¤„ç†" tabindex="-1"><a class="header-anchor" href="#_3-é”™è¯¯å¤„ç†" aria-hidden="true">#</a> 3. é”™è¯¯å¤„ç†</h4><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> vllm <span class="token keyword">import</span> LLM<span class="token punctuation">,</span> SamplingParams
<span class="token keyword">import</span> logging

<span class="token comment"># è®¾ç½®æ—¥å¿—</span>
logging<span class="token punctuation">.</span>basicConfig<span class="token punctuation">(</span>level<span class="token operator">=</span>logging<span class="token punctuation">.</span>INFO<span class="token punctuation">)</span>

<span class="token keyword">try</span><span class="token punctuation">:</span>
    llm <span class="token operator">=</span> LLM<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">&quot;meta-llama/Llama-3-8B&quot;</span><span class="token punctuation">)</span>
    outputs <span class="token operator">=</span> llm<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>
        prompts<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&quot;æµ‹è¯•&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        sampling_params<span class="token operator">=</span>SamplingParams<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
<span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>
    logging<span class="token punctuation">.</span>error<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;æ¨ç†å¤±è´¥: </span><span class="token interpolation"><span class="token punctuation">{</span>e<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
    <span class="token comment"># é™çº§å¤„ç†</span>
    outputs <span class="token operator">=</span> fallback_generate<span class="token punctuation">(</span>prompts<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="ollamaæœ€ä½³å®è·µ" tabindex="-1"><a class="header-anchor" href="#ollamaæœ€ä½³å®è·µ" aria-hidden="true">#</a> Ollamaæœ€ä½³å®è·µ</h3><h4 id="_1-æ¨¡å‹ç®¡ç†" tabindex="-1"><a class="header-anchor" href="#_1-æ¨¡å‹ç®¡ç†" aria-hidden="true">#</a> 1. æ¨¡å‹ç®¡ç†</h4><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># æŸ¥çœ‹å·²å®‰è£…æ¨¡å‹</span>
ollama list

<span class="token comment"># æ›´æ–°æ¨¡å‹</span>
ollama pull llama3:8b

<span class="token comment"># åˆ é™¤æ¨¡å‹</span>
ollama <span class="token function">rm</span> llama3:8b

<span class="token comment"># åˆ›å»ºæ¨¡å‹å‰¯æœ¬</span>
ollama <span class="token function">cp</span> llama3:8b my-model
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_2-å‚æ•°è°ƒä¼˜" tabindex="-1"><a class="header-anchor" href="#_2-å‚æ•°è°ƒä¼˜" aria-hidden="true">#</a> 2. å‚æ•°è°ƒä¼˜</h4><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># è°ƒæ•´æ¸©åº¦</span>
ollama run llama3:8b <span class="token parameter variable">--temperature</span> <span class="token number">0.7</span> <span class="token string">&quot;ä½ å¥½&quot;</span>

<span class="token comment"># è°ƒæ•´Top-P</span>
ollama run llama3:8b <span class="token parameter variable">--top_p</span> <span class="token number">0.9</span> <span class="token string">&quot;ä½ å¥½&quot;</span>

<span class="token comment"># è®¾ç½®æœ€å¤§tokenæ•°</span>
ollama run llama3:8b <span class="token parameter variable">--num_ctx</span> <span class="token number">4096</span> <span class="token string">&quot;ä½ å¥½&quot;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_3-apié›†æˆ" tabindex="-1"><a class="header-anchor" href="#_3-apié›†æˆ" aria-hidden="true">#</a> 3. APIé›†æˆ</h4><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> requests

<span class="token comment"># è°ƒç”¨Ollama API</span>
response <span class="token operator">=</span> requests<span class="token punctuation">.</span>post<span class="token punctuation">(</span>
    <span class="token string">&quot;http://localhost:11434/api/generate&quot;</span><span class="token punctuation">,</span>
    json<span class="token operator">=</span><span class="token punctuation">{</span>
        <span class="token string">&quot;model&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;llama3:8b&quot;</span><span class="token punctuation">,</span>
        <span class="token string">&quot;prompt&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;ä½ å¥½&quot;</span><span class="token punctuation">,</span>
        <span class="token string">&quot;stream&quot;</span><span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
        <span class="token string">&quot;options&quot;</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
            <span class="token string">&quot;temperature&quot;</span><span class="token punctuation">:</span> <span class="token number">0.7</span><span class="token punctuation">,</span>
            <span class="token string">&quot;num_predict&quot;</span><span class="token punctuation">:</span> <span class="token number">1000</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">)</span>

result <span class="token operator">=</span> response<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">[</span><span class="token string">&quot;response&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="é€‰å‹å»ºè®®" tabindex="-1"><a class="header-anchor" href="#é€‰å‹å»ºè®®" aria-hidden="true">#</a> é€‰å‹å»ºè®®</h2><h3 id="å†³ç­–æ ‘" tabindex="-1"><a class="header-anchor" href="#å†³ç­–æ ‘" aria-hidden="true">#</a> å†³ç­–æ ‘</h3><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>å¼€å§‹
  â”‚
  â”œâ”€ æ˜¯å¦éœ€è¦é«˜å¹¶å‘æœåŠ¡ï¼Ÿ
  â”‚   â”œâ”€ æ˜¯ â†’ é€‰æ‹©vLLM
  â”‚   â””â”€ å¦ â†’ ç»§ç»­
  â”‚
  â”œâ”€ æ˜¯å¦æ˜¯ä¼ä¸šçº§ç”Ÿäº§ç¯å¢ƒï¼Ÿ
  â”‚   â”œâ”€ æ˜¯ â†’ é€‰æ‹©vLLM
  â”‚   â””â”€ å¦ â†’ ç»§ç»­
  â”‚
  â”œâ”€ æ˜¯å¦éœ€è¦å¿«é€ŸåŸå‹å¼€å‘ï¼Ÿ
  â”‚   â”œâ”€ æ˜¯ â†’ é€‰æ‹©Ollama
  â”‚   â””â”€ å¦ â†’ ç»§ç»­
  â”‚
  â”œâ”€ ç¡¬ä»¶èµ„æºæ˜¯å¦æœ‰é™ï¼Ÿ
  â”‚   â”œâ”€ æ˜¯ â†’ é€‰æ‹©Ollama
  â”‚   â””â”€ å¦ â†’ ç»§ç»­
  â”‚
  â””â”€ ç»¼åˆéœ€æ±‚ â†’ æ··åˆéƒ¨ç½²
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="æ¨èæ–¹æ¡ˆ" tabindex="-1"><a class="header-anchor" href="#æ¨èæ–¹æ¡ˆ" aria-hidden="true">#</a> æ¨èæ–¹æ¡ˆ</h3><h4 id="æ–¹æ¡ˆ1-ä¸ªäººå¼€å‘" tabindex="-1"><a class="header-anchor" href="#æ–¹æ¡ˆ1-ä¸ªäººå¼€å‘" aria-hidden="true">#</a> æ–¹æ¡ˆ1ï¼šä¸ªäººå¼€å‘</h4><p><strong>æ¨èï¼š</strong> Ollama</p><p><strong>åŸå› ï¼š</strong></p><ul><li>ä¸€é”®éƒ¨ç½²</li><li>ç®€å•æ˜“ç”¨</li><li>èµ„æºå ç”¨ä½</li></ul><p><strong>é…ç½®ï¼š</strong></p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># å®‰è£…Ollama</span>
<span class="token function">curl</span> <span class="token parameter variable">-fsSL</span> https://ollama.com/install.sh <span class="token operator">|</span> <span class="token function">sh</span>

<span class="token comment"># æ‹‰å–è½»é‡æ¨¡å‹</span>
ollama pull llama3:8b

<span class="token comment"># è¿è¡Œ</span>
ollama run llama3:8b
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="æ–¹æ¡ˆ2-å°å‹å›¢é˜Ÿ" tabindex="-1"><a class="header-anchor" href="#æ–¹æ¡ˆ2-å°å‹å›¢é˜Ÿ" aria-hidden="true">#</a> æ–¹æ¡ˆ2ï¼šå°å‹å›¢é˜Ÿ</h4><p><strong>æ¨èï¼š</strong> Ollama + vLLMæ··åˆ</p><p><strong>æ¶æ„ï¼š</strong></p><ul><li>å¼€å‘ç¯å¢ƒï¼šOllama</li><li>æµ‹è¯•ç¯å¢ƒï¼šOllama</li><li>ç”Ÿäº§ç¯å¢ƒï¼švLLM</li></ul><p><strong>é…ç½®ï¼š</strong></p><div class="language-yaml line-numbers-mode" data-ext="yml"><pre class="language-yaml"><code><span class="token comment"># å¼€å‘ç¯å¢ƒ</span>
<span class="token key atrule">dev</span><span class="token punctuation">:</span>
  <span class="token key atrule">framework</span><span class="token punctuation">:</span> ollama
  <span class="token key atrule">model</span><span class="token punctuation">:</span> llama3<span class="token punctuation">-</span>8b
  <span class="token key atrule">quantization</span><span class="token punctuation">:</span> int4

<span class="token comment"># ç”Ÿäº§ç¯å¢ƒ</span>
<span class="token key atrule">prod</span><span class="token punctuation">:</span>
  <span class="token key atrule">framework</span><span class="token punctuation">:</span> vllm
  <span class="token key atrule">model</span><span class="token punctuation">:</span> meta<span class="token punctuation">-</span>llama/Llama<span class="token punctuation">-</span>3<span class="token punctuation">-</span>8B
  <span class="token key atrule">tensor_parallel_size</span><span class="token punctuation">:</span> <span class="token number">2</span>
  <span class="token key atrule">gpu_memory_utilization</span><span class="token punctuation">:</span> <span class="token number">0.9</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="æ–¹æ¡ˆ3-ä¼ä¸šçº§æœåŠ¡" tabindex="-1"><a class="header-anchor" href="#æ–¹æ¡ˆ3-ä¼ä¸šçº§æœåŠ¡" aria-hidden="true">#</a> æ–¹æ¡ˆ3ï¼šä¼ä¸šçº§æœåŠ¡</h4><p><strong>æ¨èï¼š</strong> vLLM</p><p><strong>åŸå› ï¼š</strong></p><ul><li>é«˜ååé‡</li><li>ä½å»¶è¿Ÿ</li><li>ç¨³å®šå¯é </li><li>ä¼ä¸šçº§æ”¯æŒ</li></ul><p><strong>é…ç½®ï¼š</strong></p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> vllm <span class="token keyword">import</span> LLM

<span class="token comment"># ç”Ÿäº§çº§é…ç½®</span>
llm <span class="token operator">=</span> LLM<span class="token punctuation">(</span>
    model<span class="token operator">=</span><span class="token string">&quot;meta-llama/Llama-3-70B&quot;</span><span class="token punctuation">,</span>
    tensor_parallel_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>
    pipeline_parallel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
    gpu_memory_utilization<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span>
    max_model_len<span class="token operator">=</span><span class="token number">16384</span><span class="token punctuation">,</span>
    enable_prefix_caching<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    disable_log_stats<span class="token operator">=</span><span class="token boolean">False</span>
<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="æ€§èƒ½ä¼˜åŒ–" tabindex="-1"><a class="header-anchor" href="#æ€§èƒ½ä¼˜åŒ–" aria-hidden="true">#</a> æ€§èƒ½ä¼˜åŒ–</h2><h3 id="vllmä¼˜åŒ–æŠ€å·§" tabindex="-1"><a class="header-anchor" href="#vllmä¼˜åŒ–æŠ€å·§" aria-hidden="true">#</a> vLLMä¼˜åŒ–æŠ€å·§</h3><h4 id="_1-å¯ç”¨å‰ç¼€ç¼“å­˜" tabindex="-1"><a class="header-anchor" href="#_1-å¯ç”¨å‰ç¼€ç¼“å­˜" aria-hidden="true">#</a> 1. å¯ç”¨å‰ç¼€ç¼“å­˜</h4><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>llm <span class="token operator">=</span> LLM<span class="token punctuation">(</span>
    model<span class="token operator">=</span><span class="token string">&quot;meta-llama/Llama-3-8B&quot;</span><span class="token punctuation">,</span>
    enable_prefix_caching<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_2-ä¼˜åŒ–kv-cache" tabindex="-1"><a class="header-anchor" href="#_2-ä¼˜åŒ–kv-cache" aria-hidden="true">#</a> 2. ä¼˜åŒ–KV Cache</h4><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>llm <span class="token operator">=</span> LLM<span class="token punctuation">(</span>
    model<span class="token operator">=</span><span class="token string">&quot;meta-llama/Llama-3-8B&quot;</span><span class="token punctuation">,</span>
    block_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    max_num_seqs<span class="token operator">=</span><span class="token number">256</span>
<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_3-ä½¿ç”¨flash-attention-2" tabindex="-1"><a class="header-anchor" href="#_3-ä½¿ç”¨flash-attention-2" aria-hidden="true">#</a> 3. ä½¿ç”¨Flash Attention 2</h4><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>llm <span class="token operator">=</span> LLM<span class="token punctuation">(</span>
    model<span class="token operator">=</span><span class="token string">&quot;meta-llama/Llama-3-8B&quot;</span><span class="token punctuation">,</span>
    enable_flash_attn<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="ollamaä¼˜åŒ–æŠ€å·§" tabindex="-1"><a class="header-anchor" href="#ollamaä¼˜åŒ–æŠ€å·§" aria-hidden="true">#</a> Ollamaä¼˜åŒ–æŠ€å·§</h3><h4 id="_1-ä½¿ç”¨é‡åŒ–æ¨¡å‹" tabindex="-1"><a class="header-anchor" href="#_1-ä½¿ç”¨é‡åŒ–æ¨¡å‹" aria-hidden="true">#</a> 1. ä½¿ç”¨é‡åŒ–æ¨¡å‹</h4><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># æ‹‰å–INT4é‡åŒ–æ¨¡å‹</span>
ollama pull llama3:8b-q4_0

<span class="token comment"># è¿è¡Œé‡åŒ–æ¨¡å‹</span>
ollama run llama3:8b-q4_0
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_2-è°ƒæ•´ä¸Šä¸‹æ–‡é•¿åº¦" tabindex="-1"><a class="header-anchor" href="#_2-è°ƒæ•´ä¸Šä¸‹æ–‡é•¿åº¦" aria-hidden="true">#</a> 2. è°ƒæ•´ä¸Šä¸‹æ–‡é•¿åº¦</h4><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># è®¾ç½®è¾ƒå°çš„ä¸Šä¸‹æ–‡é•¿åº¦</span>
ollama run llama3:8b <span class="token parameter variable">--num_ctx</span> <span class="token number">2048</span> <span class="token string">&quot;ä½ å¥½&quot;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_3-ä½¿ç”¨gpuåŠ é€Ÿ" tabindex="-1"><a class="header-anchor" href="#_3-ä½¿ç”¨gpuåŠ é€Ÿ" aria-hidden="true">#</a> 3. ä½¿ç”¨GPUåŠ é€Ÿ</h4><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># æŒ‡å®šGPU</span>
<span class="token assign-left variable">CUDA_VISIBLE_DEVICES</span><span class="token operator">=</span><span class="token number">0</span> ollama run llama3:8b
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="ç›‘æ§ä¸è°ƒè¯•" tabindex="-1"><a class="header-anchor" href="#ç›‘æ§ä¸è°ƒè¯•" aria-hidden="true">#</a> ç›‘æ§ä¸è°ƒè¯•</h2><h3 id="vllmç›‘æ§" tabindex="-1"><a class="header-anchor" href="#vllmç›‘æ§" aria-hidden="true">#</a> vLLMç›‘æ§</h3><h4 id="_1-æ€§èƒ½æŒ‡æ ‡" tabindex="-1"><a class="header-anchor" href="#_1-æ€§èƒ½æŒ‡æ ‡" aria-hidden="true">#</a> 1. æ€§èƒ½æŒ‡æ ‡</h4><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> vllm<span class="token punctuation">.</span>engine<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> Metrics

<span class="token comment"># è·å–æ€§èƒ½æŒ‡æ ‡</span>
metrics <span class="token operator">=</span> Metrics<span class="token punctuation">.</span>get_metrics<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;ååé‡: </span><span class="token interpolation"><span class="token punctuation">{</span>metrics<span class="token punctuation">.</span>throughput<span class="token punctuation">}</span></span><span class="token string"> tokens/s&quot;</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;å»¶è¿Ÿ: </span><span class="token interpolation"><span class="token punctuation">{</span>metrics<span class="token punctuation">.</span>latency<span class="token punctuation">}</span></span><span class="token string"> ms&quot;</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;GPUåˆ©ç”¨ç‡: </span><span class="token interpolation"><span class="token punctuation">{</span>metrics<span class="token punctuation">.</span>gpu_utilization<span class="token punctuation">}</span></span><span class="token string">%&quot;</span></span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_2-æ—¥å¿—åˆ†æ" tabindex="-1"><a class="header-anchor" href="#_2-æ—¥å¿—åˆ†æ" aria-hidden="true">#</a> 2. æ—¥å¿—åˆ†æ</h4><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># å¯ç”¨è¯¦ç»†æ—¥å¿—</span>
<span class="token keyword">import</span> logging

logging<span class="token punctuation">.</span>basicConfig<span class="token punctuation">(</span>
    level<span class="token operator">=</span>logging<span class="token punctuation">.</span>DEBUG<span class="token punctuation">,</span>
    <span class="token builtin">format</span><span class="token operator">=</span><span class="token string">&#39;%(asctime)s - %(name)s - %(levelname)s - %(message)s&#39;</span>
<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="ollamaç›‘æ§" tabindex="-1"><a class="header-anchor" href="#ollamaç›‘æ§" aria-hidden="true">#</a> Ollamaç›‘æ§</h3><h4 id="_1-æ¨¡å‹çŠ¶æ€" tabindex="-1"><a class="header-anchor" href="#_1-æ¨¡å‹çŠ¶æ€" aria-hidden="true">#</a> 1. æ¨¡å‹çŠ¶æ€</h4><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># æŸ¥çœ‹æ¨¡å‹çŠ¶æ€</span>
ollama <span class="token function">ps</span>

<span class="token comment"># æŸ¥çœ‹æ¨¡å‹ä¿¡æ¯</span>
ollama show llama3:8b
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_2-æ—¥å¿—æŸ¥çœ‹" tabindex="-1"><a class="header-anchor" href="#_2-æ—¥å¿—æŸ¥çœ‹" aria-hidden="true">#</a> 2. æ—¥å¿—æŸ¥çœ‹</h4><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># æŸ¥çœ‹æ—¥å¿—</span>
journalctl <span class="token parameter variable">-u</span> ollama <span class="token parameter variable">-f</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="æ•…éšœæ’æŸ¥" tabindex="-1"><a class="header-anchor" href="#æ•…éšœæ’æŸ¥" aria-hidden="true">#</a> æ•…éšœæ’æŸ¥</h2><h3 id="å¸¸è§é—®é¢˜" tabindex="-1"><a class="header-anchor" href="#å¸¸è§é—®é¢˜" aria-hidden="true">#</a> å¸¸è§é—®é¢˜</h3><h4 id="_1-vllmé—®é¢˜" tabindex="-1"><a class="header-anchor" href="#_1-vllmé—®é¢˜" aria-hidden="true">#</a> 1. vLLMé—®é¢˜</h4><p><strong>é—®é¢˜ï¼š</strong> CUDA Out of Memory</p><p><strong>è§£å†³ï¼š</strong></p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># å‡å°‘å¹¶å‘æ•°</span>
llm <span class="token operator">=</span> LLM<span class="token punctuation">(</span>
    model<span class="token operator">=</span><span class="token string">&quot;meta-llama/Llama3-8B&quot;</span><span class="token punctuation">,</span>
    max_num_seqs<span class="token operator">=</span><span class="token number">64</span>
<span class="token punctuation">)</span>

<span class="token comment"># é™ä½GPUå†…å­˜åˆ©ç”¨ç‡</span>
llm <span class="token operator">=</span> LLM<span class="token punctuation">(</span>
    model<span class="token operator">=</span><span class="token string">&quot;meta-llama/Llama-3-8B&quot;</span><span class="token punctuation">,</span>
    gpu_memory_utilization<span class="token operator">=</span><span class="token number">0.7</span>
<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>é—®é¢˜ï¼š</strong> æ¨ç†é€Ÿåº¦æ…¢</p><p><strong>è§£å†³ï¼š</strong></p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># å¯ç”¨Flash Attention</span>
llm <span class="token operator">=</span> LLM<span class="token punctuation">(</span>
    model<span class="token operator">=</span><span class="token string">&quot;meta-llama/Llama-3-8B&quot;</span><span class="token punctuation">,</span>
    enable_flash_attn<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>

<span class="token comment"># å¢åŠ tensorå¹¶è¡Œ</span>
llm <span class="token operator">=</span> LLM<span class="token punctuation">(</span>
    model<span class="token operator">=</span><span class="token string">&quot;meta-llama/Llama-3-8B&quot;</span><span class="token punctuation">,</span>
    tensor_parallel_size<span class="token operator">=</span><span class="token number">4</span>
<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_2-ollamaé—®é¢˜" tabindex="-1"><a class="header-anchor" href="#_2-ollamaé—®é¢˜" aria-hidden="true">#</a> 2. Ollamaé—®é¢˜</h4><p><strong>é—®é¢˜ï¼š</strong> æ¨¡å‹ä¸‹è½½å¤±è´¥</p><p><strong>è§£å†³ï¼š</strong></p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># ä½¿ç”¨é•œåƒæº</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">OLLAMA_HOST</span><span class="token operator">=</span>https://ollama.com
ollama pull llama3:8b
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>é—®é¢˜ï¼š</strong> æ¨ç†é€Ÿåº¦æ…¢</p><p><strong>è§£å†³ï¼š</strong></p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># ä½¿ç”¨GPUåŠ é€Ÿ</span>
<span class="token assign-left variable">CUDA_VISIBLE_DEVICES</span><span class="token operator">=</span><span class="token number">0</span> ollama run llama3:8b

<span class="token comment"># ä½¿ç”¨æ›´å°çš„æ¨¡å‹</span>
ollama pull llama3:8b-q4_0
ollama run llama3:8b-q4_0
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="æœªæ¥å±•æœ›" tabindex="-1"><a class="header-anchor" href="#æœªæ¥å±•æœ›" aria-hidden="true">#</a> æœªæ¥å±•æœ›</h2><h3 id="vllmå‘å±•æ–¹å‘" tabindex="-1"><a class="header-anchor" href="#vllmå‘å±•æ–¹å‘" aria-hidden="true">#</a> vLLMå‘å±•æ–¹å‘</h3><ol><li><p><strong>å¤šæ¨¡æ€æ”¯æŒ</strong></p><ul><li>åŸç”Ÿå¤šæ¨¡æ€æ¨ç†</li><li>è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶</li></ul></li><li><p><strong>æ›´é«˜æ•ˆçš„æ¶æ„</strong></p><ul><li>æ–°çš„æ³¨æ„åŠ›æœºåˆ¶</li><li>æ›´å¥½çš„å¹¶è¡Œç­–ç•¥</li></ul></li><li><p><strong>äº‘åŸç”Ÿéƒ¨ç½²</strong></p><ul><li>Kubernetesé›†æˆ</li><li>è‡ªåŠ¨æ‰©ç¼©å®¹</li></ul></li></ol><h3 id="ollamaå‘å±•æ–¹å‘" tabindex="-1"><a class="header-anchor" href="#ollamaå‘å±•æ–¹å‘" aria-hidden="true">#</a> Ollamaå‘å±•æ–¹å‘</h3><ol><li><p><strong>è½»é‡åŒ–ä¼˜åŒ–</strong></p><ul><li>æ›´å°çš„æ¨¡å‹æ”¯æŒ</li><li>ç§»åŠ¨ç«¯ä¼˜åŒ–</li></ul></li><li><p><strong>ç”Ÿæ€æ‰©å±•</strong></p><ul><li>æ›´å¤šæ¨¡å‹æ ¼å¼æ”¯æŒ</li><li>æ›´ä¸°å¯Œçš„å·¥å…·é›†æˆ</li></ul></li><li><p><strong>ä¼ä¸šçº§åŠŸèƒ½</strong></p><ul><li>å¤šç”¨æˆ·æ”¯æŒ</li><li>è®¿é—®æ§åˆ¶</li><li>ç›‘æ§å‘Šè­¦</li></ul></li></ol><h2 id="æ€»ç»“" tabindex="-1"><a class="header-anchor" href="#æ€»ç»“" aria-hidden="true">#</a> æ€»ç»“</h2><p>vLLMå’ŒOllamaå„æœ‰ä¼˜åŠ¿ï¼Œé€‚åˆä¸åŒçš„ä½¿ç”¨åœºæ™¯ï¼š</p><p><strong>vLLMé€‚åˆï¼š</strong></p><ul><li>ä¼ä¸šçº§ç”Ÿäº§ç¯å¢ƒ</li><li>é«˜å¹¶å‘APIæœåŠ¡</li><li>å¤šæ¨¡å‹å¹¶å‘æœåŠ¡</li><li>åˆ†å¸ƒå¼éƒ¨ç½²</li></ul><p><strong>Ollamaé€‚åˆï¼š</strong></p><ul><li>ä¸ªäººå¼€å‘å®éªŒ</li><li>å¿«é€ŸåŸå‹å¼€å‘</li><li>è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²</li><li>è½»é‡åŒ–åœºæ™¯</li></ul><p><strong>é€‰æ‹©å»ºè®®ï¼š</strong></p><ul><li>ä¸ªäººå¼€å‘ï¼šOllama</li><li>å°å‹å›¢é˜Ÿï¼šOllama + vLLMæ··åˆ</li><li>ä¼ä¸šæœåŠ¡ï¼švLLM</li></ul><p>æ ¹æ®ä½ çš„å…·ä½“éœ€æ±‚ã€ç¡¬ä»¶èµ„æºå’Œåº”ç”¨åœºæ™¯ï¼Œé€‰æ‹©æœ€é€‚åˆçš„éƒ¨ç½²æ¡†æ¶ï¼Œæ‰èƒ½å……åˆ†å‘æŒ¥å¤§æ¨¡å‹çš„ä»·å€¼ã€‚</p><hr><p><strong>å‚è€ƒèµ„æ–™ï¼š</strong></p><ul><li><a href="https://docs.vllm.ai/" target="_blank" rel="noopener noreferrer">vLLMå®˜æ–¹æ–‡æ¡£<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://ollama.com/" target="_blank" rel="noopener noreferrer">Ollamaå®˜æ–¹æ–‡æ¡£<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://github.com/vllm-project/vllm" target="_blank" rel="noopener noreferrer">vLLM GitHub<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://github.com/ollama/ollama" target="_blank" rel="noopener noreferrer">Ollama GitHub<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul></div><!--[--><!--]--></div><footer class="page-meta"><!----><div class="meta-item last-updated"><span class="meta-item-label">æœ€åæ›´æ–°: </span><!----></div><div class="meta-item contributors"><span class="meta-item-label">è´¡çŒ®è€…: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: 491750329@qq.com">kevin12369</span><!----><!--]--><!--]--></span></div></footer><!----><!--[--><!--]--></main><!--]--></div><!----><!--]--></div>
    <script type="module" src="/assets/app-D2t769wk.js" defer></script>
  </body>
</html>
